sh: line 1: logger: command not found
/apps/conda/25.3.1/etc/profile.d/conda.sh: line 69: dirname: command not found
/apps/conda/25.3.1/etc/profile.d/conda.sh: line 69: dirname: command not found
/apps/conda/25.3.1/etc/profile.d/mamba.sh: line 59: basename: command not found
Error unknown MAMBA_EXE: "/apps/conda/25.3.1/bin/mamba", filename must be mamba or micromamba
Lmod has detected the following error: This module can only be used on RHEL9
nodes. 
While processing the following module(s):
    Module fullname  Module Filename
    ---------------  ---------------
    gcc/14.2.0       /apps/lmod/modulefiles/core/gcc/14.2.0.lua

pointnet_isthmuscingulate_fs_65.py
/blue/stevenweisberg/ashishkumarsahoo/hippocampAI/conda_pyg_070923/lib/python3.8/site-packages/torch/cuda/__init__.py:155: UserWarning: 
NVIDIA B200 with CUDA capability sm_100 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 compute_37.
If you want to use the NVIDIA B200 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
Number of GPUs available for training: 1
Fold 1
Epoch: 00, Training Loss: 0.0788, Train MSE: 0.0788, r (train): 0.3019, Test MSE: 0.1275, r (test): 0.1093
Epoch: 01, Training Loss: 0.1161, Train MSE: 0.1161, r (train): -0.1099, Test MSE: 0.0881, r (test): 0.0068
Epoch: 02, Training Loss: 0.0792, Train MSE: 0.0792, r (train): 0.3428, Test MSE: 0.1960, r (test): 0.1208
Epoch: 03, Training Loss: 0.0799, Train MSE: 0.0799, r (train): 0.0362, Test MSE: 0.0781, r (test): 0.1102
Epoch: 04, Training Loss: 0.0695, Train MSE: 0.0695, r (train): 0.3744, Test MSE: 0.1916, r (test): 0.1104
Epoch: 05, Training Loss: 0.0643, Train MSE: 0.0643, r (train): 0.3245, Test MSE: 0.0818, r (test): 0.1104
Epoch: 06, Training Loss: 0.0583, Train MSE: 0.0583, r (train): 0.4578, Test MSE: 0.1323, r (test): 0.1165
Epoch: 07, Training Loss: 0.0587, Train MSE: 0.0587, r (train): 0.4711, Test MSE: 0.0976, r (test): 0.1190
Epoch: 08, Training Loss: 0.0559, Train MSE: 0.0559, r (train): 0.5059, Test MSE: 0.1248, r (test): 0.1188
Epoch: 09, Training Loss: 0.0564, Train MSE: 0.0564, r (train): 0.5211, Test MSE: 0.1043, r (test): 0.1225
Epoch: 10, Training Loss: 0.0548, Train MSE: 0.0548, r (train): 0.5430, Test MSE: 0.1178, r (test): 0.1153
Epoch: 11, Training Loss: 0.0558, Train MSE: 0.0558, r (train): 0.5217, Test MSE: 0.1037, r (test): 0.1342
Epoch: 12, Training Loss: 0.0530, Train MSE: 0.0530, r (train): 0.5675, Test MSE: 0.1195, r (test): 0.1271
Epoch: 13, Training Loss: 0.0545, Train MSE: 0.0545, r (train): 0.5473, Test MSE: 0.1047, r (test): 0.1330
Epoch: 14, Training Loss: 0.0515, Train MSE: 0.0515, r (train): 0.5995, Test MSE: 0.1138, r (test): 0.1350
Epoch: 15, Training Loss: 0.0521, Train MSE: 0.0521, r (train): 0.5897, Test MSE: 0.1057, r (test): 0.1293
Epoch: 16, Training Loss: 0.0499, Train MSE: 0.0499, r (train): 0.6359, Test MSE: 0.1044, r (test): 0.1454
Epoch: 17, Training Loss: 0.0488, Train MSE: 0.0488, r (train): 0.6475, Test MSE: 0.1004, r (test): 0.1552
Epoch: 18, Training Loss: 0.0470, Train MSE: 0.0470, r (train): 0.6775, Test MSE: 0.1036, r (test): 0.1490
Epoch: 19, Training Loss: 0.0456, Train MSE: 0.0456, r (train): 0.6880, Test MSE: 0.1013, r (test): 0.1539
Epoch: 20, Training Loss: 0.0432, Train MSE: 0.0432, r (train): 0.7306, Test MSE: 0.0977, r (test): 0.1583
Epoch: 21, Training Loss: 0.0409, Train MSE: 0.0409, r (train): 0.7277, Test MSE: 0.1045, r (test): 0.1552
Epoch: 22, Training Loss: 0.0383, Train MSE: 0.0383, r (train): 0.7875, Test MSE: 0.0925, r (test): 0.1737
Epoch: 23, Training Loss: 0.0437, Train MSE: 0.0437, r (train): 0.6491, Test MSE: 0.1196, r (test): 0.1444
Epoch: 24, Training Loss: 0.0383, Train MSE: 0.0383, r (train): 0.7946, Test MSE: 0.1020, r (test): 0.1382
Epoch: 25, Training Loss: 0.0310, Train MSE: 0.0310, r (train): 0.8236, Test MSE: 0.0961, r (test): 0.1211
Epoch: 26, Training Loss: 0.0341, Train MSE: 0.0341, r (train): 0.8746, Test MSE: 0.1210, r (test): 0.1021
Epoch: 27, Training Loss: 0.0253, Train MSE: 0.0253, r (train): 0.8726, Test MSE: 0.1346, r (test): 0.0828
Epoch: 28, Training Loss: 0.0198, Train MSE: 0.0198, r (train): 0.8838, Test MSE: 0.1551, r (test): 0.0859
Epoch: 29, Training Loss: 0.0254, Train MSE: 0.0254, r (train): 0.9179, Test MSE: 0.1410, r (test): 0.0714
Epoch: 30, Training Loss: 0.0307, Train MSE: 0.0307, r (train): 0.9100, Test MSE: 0.1402, r (test): 0.0799
Epoch: 31, Training Loss: 0.0143, Train MSE: 0.0143, r (train): 0.8953, Test MSE: 0.1942, r (test): 0.0448
Epoch: 32, Training Loss: 0.0171, Train MSE: 0.0171, r (train): 0.8824, Test MSE: 0.1463, r (test): 0.0577
Epoch: 33, Training Loss: 0.0366, Train MSE: 0.0366, r (train): 0.7958, Test MSE: 0.1280, r (test): -0.0397
Epoch: 34, Training Loss: 0.0144, Train MSE: 0.0144, r (train): 0.8953, Test MSE: 0.2229, r (test): 0.0456
Epoch: 35, Training Loss: 0.0592, Train MSE: 0.0592, r (train): 0.7598, Test MSE: 0.1323, r (test): 0.0085
Epoch: 36, Training Loss: 0.0462, Train MSE: 0.0462, r (train): 0.7348, Test MSE: 0.2468, r (test): 0.0986
Epoch: 37, Training Loss: 0.0551, Train MSE: 0.0551, r (train): 0.6230, Test MSE: 0.1113, r (test): -0.0050
Epoch: 38, Training Loss: 0.0320, Train MSE: 0.0320, r (train): 0.9262, Test MSE: 0.1260, r (test): 0.0690
Epoch: 39, Training Loss: 0.0101, Train MSE: 0.0101, r (train): 0.9580, Test MSE: 0.1220, r (test): -0.0380
Epoch: 40, Training Loss: 0.0061, Train MSE: 0.0061, r (train): 0.9586, Test MSE: 0.1494, r (test): -0.0281
Epoch: 41, Training Loss: 0.0048, Train MSE: 0.0048, r (train): 0.9676, Test MSE: 0.1417, r (test): -0.0234
Epoch: 42, Training Loss: 0.0088, Train MSE: 0.0088, r (train): 0.9726, Test MSE: 0.1204, r (test): 0.0244
Epoch: 43, Training Loss: 0.0152, Train MSE: 0.0152, r (train): 0.9708, Test MSE: 0.1326, r (test): 0.0206
Epoch: 44, Training Loss: 0.0182, Train MSE: 0.0182, r (train): 0.9671, Test MSE: 0.1400, r (test): -0.0002
Epoch: 45, Training Loss: 0.0067, Train MSE: 0.0067, r (train): 0.9614, Test MSE: 0.1414, r (test): 0.0234
Epoch: 46, Training Loss: 0.0084, Train MSE: 0.0084, r (train): 0.9440, Test MSE: 0.1608, r (test): 0.0031
Epoch: 47, Training Loss: 0.0292, Train MSE: 0.0292, r (train): 0.9428, Test MSE: 0.1224, r (test): 0.0613
Epoch: 48, Training Loss: 0.0290, Train MSE: 0.0290, r (train): 0.9625, Test MSE: 0.1479, r (test): -0.0425
Epoch: 49, Training Loss: 0.0231, Train MSE: 0.0231, r (train): 0.9551, Test MSE: 0.1517, r (test): -0.1052
Epoch: 50, Training Loss: 0.0064, Train MSE: 0.0064, r (train): 0.9650, Test MSE: 0.1421, r (test): -0.0775
Epoch: 51, Training Loss: 0.0091, Train MSE: 0.0091, r (train): 0.9414, Test MSE: 0.1445, r (test): -0.0492
Epoch: 52, Training Loss: 0.0080, Train MSE: 0.0080, r (train): 0.9455, Test MSE: 0.1375, r (test): -0.0861
Epoch: 53, Training Loss: 0.0115, Train MSE: 0.0115, r (train): 0.9464, Test MSE: 0.1434, r (test): -0.1006
Epoch: 54, Training Loss: 0.0109, Train MSE: 0.0109, r (train): 0.9487, Test MSE: 0.1477, r (test): -0.0685
Epoch: 55, Training Loss: 0.0098, Train MSE: 0.0098, r (train): 0.9401, Test MSE: 0.1687, r (test): -0.0543
Epoch: 56, Training Loss: 0.0083, Train MSE: 0.0083, r (train): 0.9596, Test MSE: 0.1678, r (test): -0.0843
Epoch: 57, Training Loss: 0.0109, Train MSE: 0.0109, r (train): 0.9547, Test MSE: 0.1643, r (test): -0.0021
Epoch: 58, Training Loss: 0.0066, Train MSE: 0.0066, r (train): 0.9568, Test MSE: 0.1376, r (test): 0.0279
Epoch: 59, Training Loss: 0.0111, Train MSE: 0.0111, r (train): 0.9406, Test MSE: 0.1367, r (test): -0.0229
Epoch: 60, Training Loss: 0.0099, Train MSE: 0.0099, r (train): 0.9351, Test MSE: 0.1602, r (test): -0.1092
Epoch: 61, Training Loss: 0.0263, Train MSE: 0.0263, r (train): 0.9308, Test MSE: 0.2017, r (test): -0.0473
Epoch: 62, Training Loss: 0.0180, Train MSE: 0.0180, r (train): 0.9481, Test MSE: 0.1796, r (test): -0.0423
Epoch: 63, Training Loss: 0.0094, Train MSE: 0.0094, r (train): 0.9360, Test MSE: 0.1396, r (test): 0.0224
Epoch: 64, Training Loss: 0.0128, Train MSE: 0.0128, r (train): 0.9459, Test MSE: 0.1545, r (test): -0.0531
Epoch: 65, Training Loss: 0.0150, Train MSE: 0.0150, r (train): 0.9316, Test MSE: 0.1457, r (test): -0.0763
Epoch: 66, Training Loss: 0.0154, Train MSE: 0.0154, r (train): 0.8943, Test MSE: 0.1824, r (test): -0.0650
Epoch: 67, Training Loss: 0.0127, Train MSE: 0.0127, r (train): 0.9140, Test MSE: 0.1501, r (test): -0.0738
Epoch: 68, Training Loss: 0.0307, Train MSE: 0.0307, r (train): 0.9038, Test MSE: 0.1684, r (test): -0.0595
Epoch: 69, Training Loss: 0.0450, Train MSE: 0.0450, r (train): 0.9043, Test MSE: 0.1731, r (test): -0.0387
Epoch: 70, Training Loss: 0.0319, Train MSE: 0.0319, r (train): 0.9124, Test MSE: 0.1723, r (test): -0.0122
Epoch: 71, Training Loss: 0.0351, Train MSE: 0.0351, r (train): 0.8999, Test MSE: 0.1728, r (test): -0.1164
Epoch: 72, Training Loss: 0.0166, Train MSE: 0.0166, r (train): 0.8882, Test MSE: 0.1831, r (test): -0.0793
Epoch: 73, Training Loss: 0.0160, Train MSE: 0.0160, r (train): 0.8936, Test MSE: 0.1670, r (test): -0.1118
Epoch: 74, Training Loss: 0.0173, Train MSE: 0.0173, r (train): 0.8836, Test MSE: 0.1200, r (test): -0.2102
Epoch: 75, Training Loss: 0.0140, Train MSE: 0.0140, r (train): 0.9071, Test MSE: 0.1534, r (test): -0.0838
Epoch: 76, Training Loss: 0.0196, Train MSE: 0.0196, r (train): 0.9236, Test MSE: 0.1820, r (test): -0.2306
Epoch: 77, Training Loss: 0.0228, Train MSE: 0.0228, r (train): 0.9429, Test MSE: 0.1856, r (test): -0.1802
Epoch: 78, Training Loss: 0.0204, Train MSE: 0.0204, r (train): 0.9426, Test MSE: 0.2019, r (test): -0.1207
Epoch: 79, Training Loss: 0.0092, Train MSE: 0.0092, r (train): 0.9456, Test MSE: 0.1584, r (test): -0.1390
Epoch: 80, Training Loss: 0.0131, Train MSE: 0.0131, r (train): 0.9245, Test MSE: 0.1638, r (test): -0.0607
Epoch: 81, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9254, Test MSE: 0.1283, r (test): -0.0088
Epoch: 82, Training Loss: 0.0170, Train MSE: 0.0170, r (train): 0.9274, Test MSE: 0.1433, r (test): -0.0595
Epoch: 83, Training Loss: 0.0142, Train MSE: 0.0142, r (train): 0.9210, Test MSE: 0.1259, r (test): -0.0469
Epoch: 84, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9155, Test MSE: 0.1512, r (test): -0.0775
Epoch: 85, Training Loss: 0.0250, Train MSE: 0.0250, r (train): 0.9147, Test MSE: 0.1729, r (test): -0.1274
Epoch: 86, Training Loss: 0.0253, Train MSE: 0.0253, r (train): 0.9353, Test MSE: 0.1827, r (test): -0.1548
Epoch: 87, Training Loss: 0.0204, Train MSE: 0.0204, r (train): 0.9404, Test MSE: 0.1739, r (test): -0.2349
Epoch: 88, Training Loss: 0.0226, Train MSE: 0.0226, r (train): 0.9501, Test MSE: 0.1960, r (test): -0.1407
Epoch: 89, Training Loss: 0.0084, Train MSE: 0.0084, r (train): 0.9397, Test MSE: 0.1373, r (test): -0.1366
Epoch: 90, Training Loss: 0.0103, Train MSE: 0.0103, r (train): 0.9388, Test MSE: 0.1551, r (test): -0.0629
Epoch: 91, Training Loss: 0.0200, Train MSE: 0.0200, r (train): 0.9340, Test MSE: 0.1151, r (test): -0.0598
Epoch: 92, Training Loss: 0.0118, Train MSE: 0.0118, r (train): 0.9290, Test MSE: 0.1541, r (test): -0.0840
Epoch: 93, Training Loss: 0.0238, Train MSE: 0.0238, r (train): 0.9283, Test MSE: 0.1670, r (test): -0.1716
Epoch: 94, Training Loss: 0.0295, Train MSE: 0.0295, r (train): 0.9267, Test MSE: 0.1866, r (test): -0.1825
Epoch: 95, Training Loss: 0.0248, Train MSE: 0.0248, r (train): 0.9477, Test MSE: 0.1995, r (test): -0.2130
Epoch: 96, Training Loss: 0.0303, Train MSE: 0.0303, r (train): 0.9223, Test MSE: 0.2238, r (test): -0.1547
Epoch: 97, Training Loss: 0.0176, Train MSE: 0.0176, r (train): 0.9202, Test MSE: 0.1962, r (test): -0.1555
Epoch: 98, Training Loss: 0.0103, Train MSE: 0.0103, r (train): 0.9315, Test MSE: 0.1401, r (test): -0.0396
Epoch: 99, Training Loss: 0.0100, Train MSE: 0.0100, r (train): 0.9369, Test MSE: 0.1629, r (test): -0.0327
Predicted tensors for training set: 
tensor([ 0.2375,  0.5249,  0.9305,  0.9625,  0.5500,  0.2937,  0.8885,  0.6264,
         0.7863,  0.4986,  0.9032,  0.6644,  0.5643,  0.8330,  0.9664,  0.8826,
         0.2117,  0.8370,  0.8450,  0.4249,  0.1200, -0.0202,  0.2740,  0.1389,
         0.6805,  0.3228,  0.2328,  0.4690, -0.0150,  0.1350,  0.4976,  0.3619,
         0.5537,  0.3307,  0.5859,  0.8330,  0.5756, -0.0136,  0.4264,  0.2394,
         0.6895,  0.7083,  0.1349,  0.2630,  0.3723,  0.4584,  0.6984,  0.4979,
         0.7510,  0.7308,  0.1884,  0.5269,  0.4547,  0.8484,  0.5906,  0.5752,
         1.0073,  0.9947,  0.5488,  1.1632,  0.7093,  0.8751,  0.2184,  0.8806,
         0.9712,  0.5334,  0.5119,  0.1253,  0.7727,  0.5962,  0.9729,  0.4425])
Target tensorsfor training set: 
tensor([0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453])
Correlation for training set: 0.9368609493920662
Predicted tensors for test set: 
tensor([-0.0344, -0.4082,  0.4474,  0.4911,  0.4202,  0.7092,  0.5918,  0.4671,
         0.5197,  0.4950,  0.6377,  0.4076,  0.5620,  0.3755,  0.6264,  0.5319,
         0.4610,  0.7948])
Target tensors for test set: 
tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246])
Correlation for test set: -0.03273832380600098
Fold 2
Epoch: 00, Training Loss: 0.0997, Train MSE: 0.0997, r (train): 0.2266, Test MSE: 0.0638, r (test): 0.2484
Epoch: 01, Training Loss: 0.0749, Train MSE: 0.0749, r (train): 0.3159, Test MSE: 0.0640, r (test): 0.2313
Epoch: 02, Training Loss: 0.0916, Train MSE: 0.0916, r (train): -0.0108, Test MSE: 0.0825, r (test): 0.1517
Epoch: 03, Training Loss: 0.0722, Train MSE: 0.0722, r (train): 0.2210, Test MSE: 0.0704, r (test): 0.1560
Epoch: 04, Training Loss: 0.0731, Train MSE: 0.0731, r (train): 0.3377, Test MSE: 0.0643, r (test): 0.2210
Epoch: 05, Training Loss: 0.0665, Train MSE: 0.0665, r (train): 0.4180, Test MSE: 0.0679, r (test): 0.1715
Epoch: 06, Training Loss: 0.0682, Train MSE: 0.0682, r (train): 0.2462, Test MSE: 0.0759, r (test): 0.1292
Epoch: 07, Training Loss: 0.0628, Train MSE: 0.0628, r (train): 0.4445, Test MSE: 0.0664, r (test): 0.1637
Epoch: 08, Training Loss: 0.0612, Train MSE: 0.0612, r (train): 0.5136, Test MSE: 0.0681, r (test): 0.1496
Epoch: 09, Training Loss: 0.0643, Train MSE: 0.0643, r (train): 0.3870, Test MSE: 0.0720, r (test): 0.1182
Epoch: 10, Training Loss: 0.0604, Train MSE: 0.0604, r (train): 0.4904, Test MSE: 0.0687, r (test): 0.1540
Epoch: 11, Training Loss: 0.0588, Train MSE: 0.0588, r (train): 0.5300, Test MSE: 0.0686, r (test): 0.1550
Epoch: 12, Training Loss: 0.0598, Train MSE: 0.0598, r (train): 0.4727, Test MSE: 0.0707, r (test): 0.1408
Epoch: 13, Training Loss: 0.0570, Train MSE: 0.0570, r (train): 0.5541, Test MSE: 0.0693, r (test): 0.1299
Epoch: 14, Training Loss: 0.0595, Train MSE: 0.0595, r (train): 0.4592, Test MSE: 0.0722, r (test): 0.1189
Epoch: 15, Training Loss: 0.0540, Train MSE: 0.0540, r (train): 0.6288, Test MSE: 0.0683, r (test): 0.1288
Epoch: 16, Training Loss: 0.0596, Train MSE: 0.0596, r (train): 0.4496, Test MSE: 0.0736, r (test): 0.1044
Epoch: 17, Training Loss: 0.0561, Train MSE: 0.0561, r (train): 0.6231, Test MSE: 0.0680, r (test): 0.1270
Epoch: 18, Training Loss: 0.0654, Train MSE: 0.0654, r (train): 0.3496, Test MSE: 0.0802, r (test): 0.0596
Epoch: 19, Training Loss: 0.0513, Train MSE: 0.0513, r (train): 0.6877, Test MSE: 0.0699, r (test): 0.0507
Epoch: 20, Training Loss: 0.0495, Train MSE: 0.0495, r (train): 0.6713, Test MSE: 0.0720, r (test): 0.0899
Epoch: 21, Training Loss: 0.0448, Train MSE: 0.0448, r (train): 0.7456, Test MSE: 0.0707, r (test): 0.1160
Epoch: 22, Training Loss: 0.0403, Train MSE: 0.0403, r (train): 0.7816, Test MSE: 0.0732, r (test): 0.0558
Epoch: 23, Training Loss: 0.0406, Train MSE: 0.0406, r (train): 0.7213, Test MSE: 0.0752, r (test): 0.0602
Epoch: 24, Training Loss: 0.0434, Train MSE: 0.0434, r (train): 0.6993, Test MSE: 0.0781, r (test): 0.0042
Epoch: 25, Training Loss: 0.0427, Train MSE: 0.0427, r (train): 0.6437, Test MSE: 0.0895, r (test): -0.0931
Epoch: 26, Training Loss: 0.0289, Train MSE: 0.0289, r (train): 0.8416, Test MSE: 0.0777, r (test): -0.0120
Epoch: 27, Training Loss: 0.0260, Train MSE: 0.0260, r (train): 0.8853, Test MSE: 0.0767, r (test): 0.0089
Epoch: 28, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.8721, Test MSE: 0.0903, r (test): 0.0064
Epoch: 29, Training Loss: 0.0239, Train MSE: 0.0239, r (train): 0.9071, Test MSE: 0.0782, r (test): -0.0133
Epoch: 30, Training Loss: 0.0267, Train MSE: 0.0267, r (train): 0.8874, Test MSE: 0.0801, r (test): -0.0364
Epoch: 31, Training Loss: 0.0192, Train MSE: 0.0192, r (train): 0.8994, Test MSE: 0.0860, r (test): -0.0621
Epoch: 32, Training Loss: 0.0220, Train MSE: 0.0220, r (train): 0.8814, Test MSE: 0.0876, r (test): -0.0525
Epoch: 33, Training Loss: 0.0282, Train MSE: 0.0282, r (train): 0.8789, Test MSE: 0.0898, r (test): -0.1572
Epoch: 34, Training Loss: 0.0433, Train MSE: 0.0433, r (train): 0.8370, Test MSE: 0.0886, r (test): -0.1211
Epoch: 35, Training Loss: 0.0420, Train MSE: 0.0420, r (train): 0.8484, Test MSE: 0.0865, r (test): -0.0968
Epoch: 36, Training Loss: 0.0260, Train MSE: 0.0260, r (train): 0.8390, Test MSE: 0.0955, r (test): -0.1204
Epoch: 37, Training Loss: 0.0332, Train MSE: 0.0332, r (train): 0.8006, Test MSE: 0.0959, r (test): -0.0868
Epoch: 38, Training Loss: 0.0279, Train MSE: 0.0279, r (train): 0.8239, Test MSE: 0.0997, r (test): -0.1278
Epoch: 39, Training Loss: 0.0325, Train MSE: 0.0325, r (train): 0.7653, Test MSE: 0.1092, r (test): -0.3238
Epoch: 40, Training Loss: 0.0493, Train MSE: 0.0493, r (train): 0.7749, Test MSE: 0.1396, r (test): -0.1456
Epoch: 41, Training Loss: 0.0366, Train MSE: 0.0366, r (train): 0.8229, Test MSE: 0.1378, r (test): -0.1558
Epoch: 42, Training Loss: 0.0318, Train MSE: 0.0318, r (train): 0.7576, Test MSE: 0.1234, r (test): -0.1586
Epoch: 43, Training Loss: 0.0148, Train MSE: 0.0148, r (train): 0.8897, Test MSE: 0.0928, r (test): -0.0147
Epoch: 44, Training Loss: 0.0170, Train MSE: 0.0170, r (train): 0.8747, Test MSE: 0.1027, r (test): 0.0053
Epoch: 45, Training Loss: 0.0193, Train MSE: 0.0193, r (train): 0.8640, Test MSE: 0.1094, r (test): 0.0219
Epoch: 46, Training Loss: 0.0232, Train MSE: 0.0232, r (train): 0.8627, Test MSE: 0.1249, r (test): -0.0215
Epoch: 47, Training Loss: 0.0279, Train MSE: 0.0279, r (train): 0.8500, Test MSE: 0.1369, r (test): -0.0732
Epoch: 48, Training Loss: 0.0302, Train MSE: 0.0302, r (train): 0.8389, Test MSE: 0.1309, r (test): -0.0380
Epoch: 49, Training Loss: 0.0246, Train MSE: 0.0246, r (train): 0.8326, Test MSE: 0.1062, r (test): 0.0135
Epoch: 50, Training Loss: 0.0269, Train MSE: 0.0269, r (train): 0.8234, Test MSE: 0.0917, r (test): -0.0011
Epoch: 51, Training Loss: 0.0268, Train MSE: 0.0268, r (train): 0.8451, Test MSE: 0.0948, r (test): -0.0043
Epoch: 52, Training Loss: 0.0251, Train MSE: 0.0251, r (train): 0.8518, Test MSE: 0.0902, r (test): -0.0104
Epoch: 53, Training Loss: 0.0553, Train MSE: 0.0553, r (train): 0.8749, Test MSE: 0.1019, r (test): -0.0560
Epoch: 54, Training Loss: 0.0823, Train MSE: 0.0823, r (train): 0.8901, Test MSE: 0.1255, r (test): -0.0543
Epoch: 55, Training Loss: 0.0658, Train MSE: 0.0658, r (train): 0.8867, Test MSE: 0.1050, r (test): -0.1259
Epoch: 56, Training Loss: 0.0712, Train MSE: 0.0712, r (train): 0.8892, Test MSE: 0.1079, r (test): -0.0700
Epoch: 57, Training Loss: 0.0599, Train MSE: 0.0599, r (train): 0.9280, Test MSE: 0.1041, r (test): -0.1102
Epoch: 58, Training Loss: 0.0353, Train MSE: 0.0353, r (train): 0.8892, Test MSE: 0.0887, r (test): -0.1158
Epoch: 59, Training Loss: 0.0171, Train MSE: 0.0171, r (train): 0.9105, Test MSE: 0.0877, r (test): 0.0077
Epoch: 60, Training Loss: 0.0125, Train MSE: 0.0125, r (train): 0.9159, Test MSE: 0.1122, r (test): -0.0418
Epoch: 61, Training Loss: 0.0131, Train MSE: 0.0131, r (train): 0.9104, Test MSE: 0.1134, r (test): 0.0168
Epoch: 62, Training Loss: 0.0142, Train MSE: 0.0142, r (train): 0.9046, Test MSE: 0.1009, r (test): -0.0284
Epoch: 63, Training Loss: 0.0206, Train MSE: 0.0206, r (train): 0.8956, Test MSE: 0.0880, r (test): 0.0080
Epoch: 64, Training Loss: 0.0527, Train MSE: 0.0527, r (train): 0.8993, Test MSE: 0.0952, r (test): 0.0426
Epoch: 65, Training Loss: 0.0683, Train MSE: 0.0683, r (train): 0.9242, Test MSE: 0.1045, r (test): -0.0017
Epoch: 66, Training Loss: 0.0739, Train MSE: 0.0739, r (train): 0.9164, Test MSE: 0.1016, r (test): -0.0273
Epoch: 67, Training Loss: 0.0346, Train MSE: 0.0346, r (train): 0.9189, Test MSE: 0.0944, r (test): -0.1063
Epoch: 68, Training Loss: 0.0127, Train MSE: 0.0127, r (train): 0.9199, Test MSE: 0.1002, r (test): -0.0811
Epoch: 69, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9055, Test MSE: 0.1022, r (test): 0.0144
Epoch: 70, Training Loss: 0.0134, Train MSE: 0.0134, r (train): 0.9154, Test MSE: 0.1068, r (test): -0.0978
Epoch: 71, Training Loss: 0.0170, Train MSE: 0.0170, r (train): 0.9015, Test MSE: 0.0892, r (test): 0.0161
Epoch: 72, Training Loss: 0.0559, Train MSE: 0.0559, r (train): 0.9090, Test MSE: 0.0961, r (test): -0.0159
Epoch: 73, Training Loss: 0.0847, Train MSE: 0.0847, r (train): 0.9091, Test MSE: 0.1049, r (test): 0.0108
Epoch: 74, Training Loss: 0.0587, Train MSE: 0.0587, r (train): 0.9115, Test MSE: 0.0972, r (test): -0.0566
Epoch: 75, Training Loss: 0.0242, Train MSE: 0.0242, r (train): 0.9074, Test MSE: 0.0824, r (test): 0.0298
Epoch: 76, Training Loss: 0.0157, Train MSE: 0.0157, r (train): 0.9084, Test MSE: 0.0913, r (test): 0.0002
Epoch: 77, Training Loss: 0.0169, Train MSE: 0.0169, r (train): 0.9099, Test MSE: 0.1246, r (test): -0.0890
Epoch: 78, Training Loss: 0.0126, Train MSE: 0.0126, r (train): 0.9160, Test MSE: 0.0962, r (test): 0.0174
Epoch: 79, Training Loss: 0.0152, Train MSE: 0.0152, r (train): 0.9057, Test MSE: 0.0955, r (test): -0.0242
Epoch: 80, Training Loss: 0.0467, Train MSE: 0.0467, r (train): 0.9056, Test MSE: 0.0983, r (test): 0.0151
Epoch: 81, Training Loss: 0.0517, Train MSE: 0.0517, r (train): 0.9145, Test MSE: 0.0834, r (test): 0.1080
Epoch: 82, Training Loss: 0.0338, Train MSE: 0.0338, r (train): 0.9340, Test MSE: 0.0901, r (test): -0.0257
Epoch: 83, Training Loss: 0.0174, Train MSE: 0.0174, r (train): 0.8880, Test MSE: 0.0850, r (test): 0.0456
Epoch: 84, Training Loss: 0.0116, Train MSE: 0.0116, r (train): 0.9324, Test MSE: 0.0983, r (test): -0.0746
Epoch: 85, Training Loss: 0.0073, Train MSE: 0.0073, r (train): 0.9468, Test MSE: 0.0962, r (test): -0.0324
Epoch: 86, Training Loss: 0.0113, Train MSE: 0.0113, r (train): 0.9372, Test MSE: 0.0882, r (test): 0.0020
Epoch: 87, Training Loss: 0.0186, Train MSE: 0.0186, r (train): 0.9299, Test MSE: 0.0846, r (test): -0.0284
Epoch: 88, Training Loss: 0.0460, Train MSE: 0.0460, r (train): 0.9282, Test MSE: 0.0842, r (test): 0.0409
Epoch: 89, Training Loss: 0.0211, Train MSE: 0.0211, r (train): 0.9036, Test MSE: 0.0726, r (test): 0.1409
Epoch: 90, Training Loss: 0.0114, Train MSE: 0.0114, r (train): 0.9344, Test MSE: 0.0929, r (test): -0.0278
Epoch: 91, Training Loss: 0.0211, Train MSE: 0.0211, r (train): 0.9232, Test MSE: 0.1228, r (test): -0.0138
Epoch: 92, Training Loss: 0.0190, Train MSE: 0.0190, r (train): 0.9221, Test MSE: 0.1219, r (test): -0.0438
Epoch: 93, Training Loss: 0.0134, Train MSE: 0.0134, r (train): 0.9134, Test MSE: 0.1046, r (test): -0.0428
Epoch: 94, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9091, Test MSE: 0.0969, r (test): -0.0536
Epoch: 95, Training Loss: 0.0237, Train MSE: 0.0237, r (train): 0.9268, Test MSE: 0.0893, r (test): -0.0180
Epoch: 96, Training Loss: 0.0264, Train MSE: 0.0264, r (train): 0.9186, Test MSE: 0.0766, r (test): 0.0759
Epoch: 97, Training Loss: 0.0133, Train MSE: 0.0133, r (train): 0.9192, Test MSE: 0.1006, r (test): -0.1356
Epoch: 98, Training Loss: 0.0095, Train MSE: 0.0095, r (train): 0.9347, Test MSE: 0.1000, r (test): -0.0954
Epoch: 99, Training Loss: 0.0221, Train MSE: 0.0221, r (train): 0.9588, Test MSE: 0.1321, r (test): -0.0533
Predicted tensors for training set: 
tensor([ 7.6411e-01, -1.4158e-01,  6.0914e-01,  5.6019e-01,  6.7161e-01,
         3.2975e-01,  1.0735e-01,  3.6606e-01,  2.6172e-01,  1.7390e-01,
        -2.1411e-01,  5.7062e-01,  5.9258e-01,  2.9186e-01,  5.5745e-01,
         6.0842e-01,  6.9115e-02, -2.3075e-01,  6.7634e-01,  2.1478e-01,
        -4.5387e-02, -9.0876e-02,  1.2544e-01, -2.5121e-02,  6.1238e-01,
         3.3745e-01,  2.4520e-01,  4.8928e-01,  1.4402e-01,  1.2092e-01,
         5.4310e-01,  4.2012e-01,  5.6247e-01,  3.5046e-01,  5.7199e-01,
         8.3523e-01,  6.0263e-01,  2.1621e-02,  4.0907e-01,  1.1564e-01,
         7.1049e-01,  6.0747e-01, -8.9500e-02,  2.3099e-02,  3.8269e-01,
         4.2121e-01,  6.1869e-01,  3.0895e-01,  6.0375e-01,  5.6366e-01,
        -2.3659e-04,  3.2654e-01,  2.2259e-01,  6.5616e-01,  4.5687e-01,
         4.7676e-01,  7.8746e-01,  8.4222e-01,  4.0120e-01,  9.3196e-01,
         5.5813e-01,  6.9640e-01,  2.8694e-02,  7.3832e-01,  8.6167e-01,
         3.9428e-01,  4.2734e-01,  7.7411e-02,  7.5924e-01,  5.6022e-01,
         8.6832e-01,  2.3768e-01])
Target tensorsfor training set: 
tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453])
Correlation for training set: 0.9587508578493485
Predicted tensors for test set: 
tensor([0.4245, 0.3343, 0.7371, 0.4159, 0.4225, 0.4622, 0.6196, 0.4475, 0.3324,
        0.2759, 0.3600, 0.3407, 0.5030, 0.3635, 0.4182, 0.3969, 0.6874, 0.3942])
Target tensors for test set: 
tensor([0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117])
Correlation for test set: -0.05326850886053058
Fold 3
Epoch: 00, Training Loss: 0.0730, Train MSE: 0.0730, r (train): 0.2537, Test MSE: 0.1084, r (test): 0.0299
Epoch: 01, Training Loss: 0.0736, Train MSE: 0.0736, r (train): 0.2904, Test MSE: 0.2333, r (test): -0.1964
Epoch: 02, Training Loss: 0.0931, Train MSE: 0.0931, r (train): 0.1878, Test MSE: 0.0566, r (test): 0.3401
Epoch: 03, Training Loss: 0.0687, Train MSE: 0.0687, r (train): 0.2684, Test MSE: 0.1530, r (test): -0.2071
Epoch: 04, Training Loss: 0.0643, Train MSE: 0.0643, r (train): 0.3446, Test MSE: 0.0904, r (test): 0.0451
Epoch: 05, Training Loss: 0.0589, Train MSE: 0.0589, r (train): 0.5147, Test MSE: 0.0879, r (test): -0.0575
Epoch: 06, Training Loss: 0.0563, Train MSE: 0.0563, r (train): 0.5422, Test MSE: 0.1024, r (test): -0.0788
Epoch: 07, Training Loss: 0.0555, Train MSE: 0.0555, r (train): 0.5159, Test MSE: 0.0919, r (test): -0.0093
Epoch: 08, Training Loss: 0.0532, Train MSE: 0.0532, r (train): 0.5675, Test MSE: 0.1081, r (test): -0.0704
Epoch: 09, Training Loss: 0.0520, Train MSE: 0.0520, r (train): 0.5714, Test MSE: 0.1014, r (test): -0.0397
Epoch: 10, Training Loss: 0.0509, Train MSE: 0.0509, r (train): 0.6000, Test MSE: 0.1290, r (test): -0.1015
Epoch: 11, Training Loss: 0.0492, Train MSE: 0.0492, r (train): 0.6036, Test MSE: 0.0995, r (test): -0.0124
Epoch: 12, Training Loss: 0.0498, Train MSE: 0.0498, r (train): 0.6265, Test MSE: 0.1912, r (test): -0.1582
Epoch: 13, Training Loss: 0.0516, Train MSE: 0.0516, r (train): 0.5411, Test MSE: 0.0856, r (test): 0.0740
Epoch: 14, Training Loss: 0.0590, Train MSE: 0.0590, r (train): 0.5207, Test MSE: 0.2526, r (test): -0.2013
Epoch: 15, Training Loss: 0.0579, Train MSE: 0.0579, r (train): 0.4727, Test MSE: 0.0681, r (test): 0.2478
Epoch: 16, Training Loss: 0.0463, Train MSE: 0.0463, r (train): 0.6710, Test MSE: 0.1360, r (test): -0.1979
Epoch: 17, Training Loss: 0.0421, Train MSE: 0.0421, r (train): 0.7091, Test MSE: 0.1062, r (test): -0.0145
Epoch: 18, Training Loss: 0.0383, Train MSE: 0.0383, r (train): 0.7568, Test MSE: 0.1731, r (test): -0.1534
Epoch: 19, Training Loss: 0.0349, Train MSE: 0.0349, r (train): 0.7638, Test MSE: 0.1638, r (test): -0.1292
Epoch: 20, Training Loss: 0.0326, Train MSE: 0.0326, r (train): 0.7794, Test MSE: 0.1779, r (test): -0.1459
Epoch: 21, Training Loss: 0.0289, Train MSE: 0.0289, r (train): 0.8136, Test MSE: 0.1515, r (test): -0.1178
Epoch: 22, Training Loss: 0.0259, Train MSE: 0.0259, r (train): 0.8293, Test MSE: 0.0989, r (test): -0.0105
Epoch: 23, Training Loss: 0.0223, Train MSE: 0.0223, r (train): 0.8580, Test MSE: 0.0867, r (test): 0.0691
Epoch: 24, Training Loss: 0.0169, Train MSE: 0.0169, r (train): 0.8900, Test MSE: 0.0940, r (test): 0.0121
Epoch: 25, Training Loss: 0.0147, Train MSE: 0.0147, r (train): 0.9060, Test MSE: 0.0649, r (test): 0.2463
Epoch: 26, Training Loss: 0.0129, Train MSE: 0.0129, r (train): 0.9173, Test MSE: 0.0791, r (test): 0.1068
Epoch: 27, Training Loss: 0.0307, Train MSE: 0.0307, r (train): 0.7713, Test MSE: 0.0694, r (test): 0.2684
Epoch: 28, Training Loss: 0.0326, Train MSE: 0.0326, r (train): 0.7570, Test MSE: 0.1674, r (test): -0.1711
Epoch: 29, Training Loss: 0.0280, Train MSE: 0.0280, r (train): 0.7838, Test MSE: 0.0882, r (test): 0.0811
Epoch: 30, Training Loss: 0.0159, Train MSE: 0.0159, r (train): 0.9027, Test MSE: 0.2436, r (test): -0.1952
Epoch: 31, Training Loss: 0.0087, Train MSE: 0.0087, r (train): 0.9462, Test MSE: 0.1540, r (test): -0.1233
Epoch: 32, Training Loss: 0.0068, Train MSE: 0.0068, r (train): 0.9532, Test MSE: 0.2113, r (test): -0.1635
Epoch: 33, Training Loss: 0.0091, Train MSE: 0.0091, r (train): 0.9588, Test MSE: 0.1338, r (test): -0.0833
Epoch: 34, Training Loss: 0.0086, Train MSE: 0.0086, r (train): 0.9547, Test MSE: 0.1771, r (test): -0.1422
Epoch: 35, Training Loss: 0.0119, Train MSE: 0.0119, r (train): 0.9561, Test MSE: 0.1043, r (test): -0.0009
Epoch: 36, Training Loss: 0.0124, Train MSE: 0.0124, r (train): 0.9305, Test MSE: 0.1480, r (test): -0.1126
Epoch: 37, Training Loss: 0.0243, Train MSE: 0.0243, r (train): 0.9330, Test MSE: 0.0681, r (test): 0.2667
Epoch: 38, Training Loss: 0.0136, Train MSE: 0.0136, r (train): 0.9377, Test MSE: 0.0667, r (test): 0.1100
Epoch: 39, Training Loss: 0.0115, Train MSE: 0.0115, r (train): 0.9435, Test MSE: 0.0623, r (test): 0.2562
Epoch: 40, Training Loss: 0.0418, Train MSE: 0.0418, r (train): 0.9580, Test MSE: 0.0768, r (test): 0.2580
Epoch: 41, Training Loss: 0.0357, Train MSE: 0.0357, r (train): 0.9301, Test MSE: 0.0703, r (test): 0.2308
Epoch: 42, Training Loss: 0.0326, Train MSE: 0.0326, r (train): 0.9380, Test MSE: 0.1010, r (test): 0.2742
Epoch: 43, Training Loss: 0.0819, Train MSE: 0.0819, r (train): 0.9060, Test MSE: 0.1236, r (test): 0.2684
Epoch: 44, Training Loss: 0.0995, Train MSE: 0.0995, r (train): 0.9036, Test MSE: 0.1258, r (test): 0.3151
Epoch: 45, Training Loss: 0.0742, Train MSE: 0.0742, r (train): 0.8887, Test MSE: 0.0948, r (test): 0.2595
Epoch: 46, Training Loss: 0.0385, Train MSE: 0.0385, r (train): 0.9076, Test MSE: 0.0696, r (test): 0.1752
Epoch: 47, Training Loss: 0.0729, Train MSE: 0.0729, r (train): 0.8974, Test MSE: 0.0979, r (test): 0.2015
Epoch: 48, Training Loss: 0.0224, Train MSE: 0.0224, r (train): 0.8820, Test MSE: 0.0818, r (test): -0.1867
Epoch: 49, Training Loss: 0.0132, Train MSE: 0.0132, r (train): 0.9179, Test MSE: 0.0678, r (test): 0.1322
Epoch: 50, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9458, Test MSE: 0.0700, r (test): 0.0641
Epoch: 51, Training Loss: 0.0157, Train MSE: 0.0157, r (train): 0.9233, Test MSE: 0.0648, r (test): 0.1367
Epoch: 52, Training Loss: 0.0147, Train MSE: 0.0147, r (train): 0.9289, Test MSE: 0.0715, r (test): 0.0664
Epoch: 53, Training Loss: 0.0191, Train MSE: 0.0191, r (train): 0.9191, Test MSE: 0.1225, r (test): -0.0936
Epoch: 54, Training Loss: 0.0354, Train MSE: 0.0354, r (train): 0.9038, Test MSE: 0.1326, r (test): -0.0017
Epoch: 55, Training Loss: 0.0488, Train MSE: 0.0488, r (train): 0.9115, Test MSE: 0.1597, r (test): -0.1980
Epoch: 56, Training Loss: 0.0449, Train MSE: 0.0449, r (train): 0.8953, Test MSE: 0.1349, r (test): 0.0419
Epoch: 57, Training Loss: 0.0370, Train MSE: 0.0370, r (train): 0.8970, Test MSE: 0.1463, r (test): -0.1099
Epoch: 58, Training Loss: 0.0292, Train MSE: 0.0292, r (train): 0.9023, Test MSE: 0.1252, r (test): -0.0014
Epoch: 59, Training Loss: 0.0430, Train MSE: 0.0430, r (train): 0.8715, Test MSE: 0.1984, r (test): -0.2515
Epoch: 60, Training Loss: 0.0149, Train MSE: 0.0149, r (train): 0.9130, Test MSE: 0.0840, r (test): 0.2029
Epoch: 61, Training Loss: 0.0221, Train MSE: 0.0221, r (train): 0.9043, Test MSE: 0.0781, r (test): 0.2506
Epoch: 62, Training Loss: 0.0484, Train MSE: 0.0484, r (train): 0.9172, Test MSE: 0.0974, r (test): 0.3162
Epoch: 63, Training Loss: 0.0429, Train MSE: 0.0429, r (train): 0.9118, Test MSE: 0.0850, r (test): 0.2557
Epoch: 64, Training Loss: 0.0457, Train MSE: 0.0457, r (train): 0.9327, Test MSE: 0.0829, r (test): 0.2629
Epoch: 65, Training Loss: 0.0313, Train MSE: 0.0313, r (train): 0.9174, Test MSE: 0.0665, r (test): 0.2509
Epoch: 66, Training Loss: 0.0202, Train MSE: 0.0202, r (train): 0.9250, Test MSE: 0.0667, r (test): 0.1772
Epoch: 67, Training Loss: 0.0158, Train MSE: 0.0158, r (train): 0.9244, Test MSE: 0.0888, r (test): -0.0272
Epoch: 68, Training Loss: 0.0357, Train MSE: 0.0357, r (train): 0.9196, Test MSE: 0.1229, r (test): 0.0355
Epoch: 69, Training Loss: 0.0227, Train MSE: 0.0227, r (train): 0.9531, Test MSE: 0.1124, r (test): -0.0169
Epoch: 70, Training Loss: 0.0080, Train MSE: 0.0080, r (train): 0.9527, Test MSE: 0.0796, r (test): 0.0467
Epoch: 71, Training Loss: 0.0154, Train MSE: 0.0154, r (train): 0.9429, Test MSE: 0.0699, r (test): 0.0665
Epoch: 72, Training Loss: 0.0691, Train MSE: 0.0691, r (train): 0.9213, Test MSE: 0.1174, r (test): 0.2508
Epoch: 73, Training Loss: 0.0775, Train MSE: 0.0775, r (train): 0.9170, Test MSE: 0.1062, r (test): 0.2014
Epoch: 74, Training Loss: 0.0316, Train MSE: 0.0316, r (train): 0.9373, Test MSE: 0.0780, r (test): -0.0982
Epoch: 75, Training Loss: 0.0096, Train MSE: 0.0096, r (train): 0.9372, Test MSE: 0.0992, r (test): -0.1733
Epoch: 76, Training Loss: 0.0264, Train MSE: 0.0264, r (train): 0.9359, Test MSE: 0.1322, r (test): -0.2190
Epoch: 77, Training Loss: 0.0255, Train MSE: 0.0255, r (train): 0.9480, Test MSE: 0.1514, r (test): -0.1690
Epoch: 78, Training Loss: 0.0060, Train MSE: 0.0060, r (train): 0.9627, Test MSE: 0.1119, r (test): -0.1290
Epoch: 79, Training Loss: 0.0267, Train MSE: 0.0267, r (train): 0.9415, Test MSE: 0.0788, r (test): 0.1147
Epoch: 80, Training Loss: 0.0506, Train MSE: 0.0506, r (train): 0.9119, Test MSE: 0.0733, r (test): 0.2307
Epoch: 81, Training Loss: 0.0384, Train MSE: 0.0384, r (train): 0.9141, Test MSE: 0.0672, r (test): 0.1993
Epoch: 82, Training Loss: 0.0088, Train MSE: 0.0088, r (train): 0.9383, Test MSE: 0.0864, r (test): -0.1129
Epoch: 83, Training Loss: 0.0316, Train MSE: 0.0316, r (train): 0.9173, Test MSE: 0.1728, r (test): -0.1993
Epoch: 84, Training Loss: 0.0229, Train MSE: 0.0229, r (train): 0.9440, Test MSE: 0.1499, r (test): -0.2103
Epoch: 85, Training Loss: 0.0099, Train MSE: 0.0099, r (train): 0.9391, Test MSE: 0.0892, r (test): -0.0281
Epoch: 86, Training Loss: 0.0186, Train MSE: 0.0186, r (train): 0.9508, Test MSE: 0.0810, r (test): -0.0324
Epoch: 87, Training Loss: 0.0446, Train MSE: 0.0446, r (train): 0.9282, Test MSE: 0.0679, r (test): 0.1913
Epoch: 88, Training Loss: 0.0176, Train MSE: 0.0176, r (train): 0.9229, Test MSE: 0.0757, r (test): -0.2053
Epoch: 89, Training Loss: 0.0198, Train MSE: 0.0198, r (train): 0.9356, Test MSE: 0.1384, r (test): -0.2945
Epoch: 90, Training Loss: 0.0240, Train MSE: 0.0240, r (train): 0.9407, Test MSE: 0.1635, r (test): -0.2221
Epoch: 91, Training Loss: 0.0068, Train MSE: 0.0068, r (train): 0.9587, Test MSE: 0.1115, r (test): -0.1616
Epoch: 92, Training Loss: 0.0394, Train MSE: 0.0394, r (train): 0.9223, Test MSE: 0.0691, r (test): 0.2197
Epoch: 93, Training Loss: 0.0373, Train MSE: 0.0373, r (train): 0.9296, Test MSE: 0.0673, r (test): 0.1804
Epoch: 94, Training Loss: 0.0086, Train MSE: 0.0086, r (train): 0.9618, Test MSE: 0.0664, r (test): 0.1305
Epoch: 95, Training Loss: 0.0266, Train MSE: 0.0266, r (train): 0.9583, Test MSE: 0.1319, r (test): 0.0786
Epoch: 96, Training Loss: 0.0407, Train MSE: 0.0407, r (train): 0.9416, Test MSE: 0.1728, r (test): -0.1053
Epoch: 97, Training Loss: 0.0146, Train MSE: 0.0146, r (train): 0.9527, Test MSE: 0.2332, r (test): -0.1702
Epoch: 98, Training Loss: 0.0148, Train MSE: 0.0148, r (train): 0.9512, Test MSE: 0.1285, r (test): -0.1179
Epoch: 99, Training Loss: 0.0452, Train MSE: 0.0452, r (train): 0.9284, Test MSE: 0.0604, r (test): 0.3846
Predicted tensors for training set: 
tensor([ 0.7689,  0.0711,  0.6096,  0.4930,  0.6941,  0.4159,  0.1466,  0.3927,
         0.1716,  0.1895, -0.1993,  0.5268,  0.5049,  0.3363,  0.4711,  0.5551,
         0.2455,  0.0126,  0.1482,  0.3528,  0.6593,  0.6822,  0.3337,  0.1235,
         0.7300,  0.5236,  0.4888,  0.3106,  0.7296,  0.4545,  0.3599,  0.6498,
         0.8206,  0.6248,  0.1123,  0.8223,  0.6050,  0.0863,  0.3628,  0.0680,
         0.6918,  0.6486, -0.0873,  0.1152,  0.3199,  0.3890,  0.4935,  0.2349,
         0.5110,  0.2926, -0.1840,  0.0899,  0.0415,  0.4219,  0.0829,  0.2800,
         0.4460,  0.3606,  0.3084,  0.5700,  0.3526,  0.4567, -0.0560,  0.6174,
         0.6966,  0.3366,  0.3729,  0.0524,  0.7023,  0.4980,  0.8312,  0.2961])
Target tensorsfor training set: 
tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453])
Correlation for training set: 0.928392847441016
Predicted tensors for test set: 
tensor([0.3114, 0.3728, 0.4433, 0.0925, 0.4103, 0.3672, 0.3741, 0.3834, 0.3050,
        0.4631, 0.3701, 0.2873, 0.4597, 0.3056, 0.5122, 0.3090, 0.2656, 0.5064])
Target tensors for test set: 
tensor([0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535])
Correlation for test set: 0.3846481711358458
Fold 4
Epoch: 00, Training Loss: 0.1230, Train MSE: 0.1230, r (train): 0.2518, Test MSE: 0.0549, r (test): 0.4351
Epoch: 01, Training Loss: 0.0745, Train MSE: 0.0745, r (train): 0.2045, Test MSE: 0.0718, r (test): 0.2454
Epoch: 02, Training Loss: 0.0930, Train MSE: 0.0930, r (train): -0.0065, Test MSE: 0.0582, r (test): 0.3289
Epoch: 03, Training Loss: 0.0822, Train MSE: 0.0822, r (train): 0.3048, Test MSE: 0.0746, r (test): 0.3868
Epoch: 04, Training Loss: 0.0625, Train MSE: 0.0625, r (train): 0.3885, Test MSE: 0.0701, r (test): 0.3224
Epoch: 05, Training Loss: 0.0830, Train MSE: 0.0830, r (train): 0.0519, Test MSE: 0.0681, r (test): 0.1721
Epoch: 06, Training Loss: 0.0702, Train MSE: 0.0702, r (train): 0.2505, Test MSE: 0.0665, r (test): 0.3469
Epoch: 07, Training Loss: 0.0646, Train MSE: 0.0646, r (train): 0.4059, Test MSE: 0.0811, r (test): 0.3719
Epoch: 08, Training Loss: 0.0590, Train MSE: 0.0590, r (train): 0.4745, Test MSE: 0.0759, r (test): 0.2651
Epoch: 09, Training Loss: 0.0741, Train MSE: 0.0741, r (train): 0.1776, Test MSE: 0.0672, r (test): 0.2511
Epoch: 10, Training Loss: 0.0617, Train MSE: 0.0617, r (train): 0.4294, Test MSE: 0.0772, r (test): 0.3569
Epoch: 11, Training Loss: 0.0554, Train MSE: 0.0554, r (train): 0.5200, Test MSE: 0.0805, r (test): 0.3174
Epoch: 12, Training Loss: 0.0577, Train MSE: 0.0577, r (train): 0.5120, Test MSE: 0.0726, r (test): 0.2388
Epoch: 13, Training Loss: 0.0628, Train MSE: 0.0628, r (train): 0.4128, Test MSE: 0.0711, r (test): 0.2941
Epoch: 14, Training Loss: 0.0571, Train MSE: 0.0571, r (train): 0.5275, Test MSE: 0.0824, r (test): 0.3402
Epoch: 15, Training Loss: 0.0515, Train MSE: 0.0515, r (train): 0.6131, Test MSE: 0.0830, r (test): 0.3006
Epoch: 16, Training Loss: 0.0520, Train MSE: 0.0520, r (train): 0.6192, Test MSE: 0.0746, r (test): 0.2574
Epoch: 17, Training Loss: 0.0521, Train MSE: 0.0521, r (train): 0.6006, Test MSE: 0.0765, r (test): 0.3033
Epoch: 18, Training Loss: 0.0505, Train MSE: 0.0505, r (train): 0.6594, Test MSE: 0.0903, r (test): 0.2932
Epoch: 19, Training Loss: 0.0469, Train MSE: 0.0469, r (train): 0.6745, Test MSE: 0.0754, r (test): 0.2522
Epoch: 20, Training Loss: 0.0454, Train MSE: 0.0454, r (train): 0.6627, Test MSE: 0.0759, r (test): 0.2769
Epoch: 21, Training Loss: 0.0466, Train MSE: 0.0466, r (train): 0.6930, Test MSE: 0.0911, r (test): 0.2465
Epoch: 22, Training Loss: 0.0405, Train MSE: 0.0405, r (train): 0.7232, Test MSE: 0.0711, r (test): 0.2255
Epoch: 23, Training Loss: 0.0398, Train MSE: 0.0398, r (train): 0.7504, Test MSE: 0.0869, r (test): 0.2139
Epoch: 24, Training Loss: 0.0338, Train MSE: 0.0338, r (train): 0.7906, Test MSE: 0.0753, r (test): 0.1803
Epoch: 25, Training Loss: 0.0307, Train MSE: 0.0307, r (train): 0.8141, Test MSE: 0.0823, r (test): 0.1883
Epoch: 26, Training Loss: 0.0301, Train MSE: 0.0301, r (train): 0.8182, Test MSE: 0.0797, r (test): 0.1625
Epoch: 27, Training Loss: 0.0319, Train MSE: 0.0319, r (train): 0.7570, Test MSE: 0.0853, r (test): 0.2311
Epoch: 28, Training Loss: 0.0685, Train MSE: 0.0685, r (train): 0.4591, Test MSE: 0.0809, r (test): -0.0209
Epoch: 29, Training Loss: 0.0520, Train MSE: 0.0520, r (train): 0.5825, Test MSE: 0.0865, r (test): 0.2160
Epoch: 30, Training Loss: 0.0433, Train MSE: 0.0433, r (train): 0.8124, Test MSE: 0.1128, r (test): 0.0935
Epoch: 31, Training Loss: 0.0265, Train MSE: 0.0265, r (train): 0.8422, Test MSE: 0.0812, r (test): 0.1406
Epoch: 32, Training Loss: 0.0362, Train MSE: 0.0362, r (train): 0.7702, Test MSE: 0.1022, r (test): 0.1637
Epoch: 33, Training Loss: 0.0217, Train MSE: 0.0217, r (train): 0.9014, Test MSE: 0.0767, r (test): 0.1309
Epoch: 34, Training Loss: 0.0247, Train MSE: 0.0247, r (train): 0.8730, Test MSE: 0.1161, r (test): 0.0610
Epoch: 35, Training Loss: 0.0105, Train MSE: 0.0105, r (train): 0.9379, Test MSE: 0.0916, r (test): 0.0880
Epoch: 36, Training Loss: 0.0279, Train MSE: 0.0279, r (train): 0.9357, Test MSE: 0.1195, r (test): 0.0806
Epoch: 37, Training Loss: 0.0163, Train MSE: 0.0163, r (train): 0.9378, Test MSE: 0.1000, r (test): 0.1237
Epoch: 38, Training Loss: 0.0064, Train MSE: 0.0064, r (train): 0.9634, Test MSE: 0.0913, r (test): 0.1121
Epoch: 39, Training Loss: 0.0095, Train MSE: 0.0095, r (train): 0.9513, Test MSE: 0.1002, r (test): 0.1684
Epoch: 40, Training Loss: 0.0063, Train MSE: 0.0063, r (train): 0.9634, Test MSE: 0.0920, r (test): 0.1113
Epoch: 41, Training Loss: 0.0132, Train MSE: 0.0132, r (train): 0.9536, Test MSE: 0.1054, r (test): 0.1541
Epoch: 42, Training Loss: 0.0173, Train MSE: 0.0173, r (train): 0.8984, Test MSE: 0.1026, r (test): 0.2096
Epoch: 43, Training Loss: 0.0306, Train MSE: 0.0306, r (train): 0.8109, Test MSE: 0.0861, r (test): -0.0715
Epoch: 44, Training Loss: 0.0297, Train MSE: 0.0297, r (train): 0.8665, Test MSE: 0.1120, r (test): 0.0891
Epoch: 45, Training Loss: 0.0189, Train MSE: 0.0189, r (train): 0.8977, Test MSE: 0.0898, r (test): -0.0631
Epoch: 46, Training Loss: 0.0094, Train MSE: 0.0094, r (train): 0.9373, Test MSE: 0.0886, r (test): 0.0114
Epoch: 47, Training Loss: 0.0061, Train MSE: 0.0061, r (train): 0.9633, Test MSE: 0.0980, r (test): 0.0590
Epoch: 48, Training Loss: 0.0055, Train MSE: 0.0055, r (train): 0.9661, Test MSE: 0.0926, r (test): 0.0294
Epoch: 49, Training Loss: 0.0080, Train MSE: 0.0080, r (train): 0.9607, Test MSE: 0.0858, r (test): 0.0345
Epoch: 50, Training Loss: 0.0169, Train MSE: 0.0169, r (train): 0.9504, Test MSE: 0.0891, r (test): -0.0116
Epoch: 51, Training Loss: 0.0290, Train MSE: 0.0290, r (train): 0.9409, Test MSE: 0.0942, r (test): -0.0053
Epoch: 52, Training Loss: 0.0530, Train MSE: 0.0530, r (train): 0.9421, Test MSE: 0.1057, r (test): 0.0843
Epoch: 53, Training Loss: 0.0426, Train MSE: 0.0426, r (train): 0.9342, Test MSE: 0.0987, r (test): 0.1084
Epoch: 54, Training Loss: 0.0330, Train MSE: 0.0330, r (train): 0.9298, Test MSE: 0.1001, r (test): 0.0372
Epoch: 55, Training Loss: 0.0185, Train MSE: 0.0185, r (train): 0.9410, Test MSE: 0.0882, r (test): 0.0915
Epoch: 56, Training Loss: 0.0121, Train MSE: 0.0121, r (train): 0.9263, Test MSE: 0.0826, r (test): 0.0544
Epoch: 57, Training Loss: 0.0214, Train MSE: 0.0214, r (train): 0.8747, Test MSE: 0.0753, r (test): 0.0559
Epoch: 58, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.9086, Test MSE: 0.0744, r (test): 0.0959
Epoch: 59, Training Loss: 0.0180, Train MSE: 0.0180, r (train): 0.9009, Test MSE: 0.0793, r (test): 0.0953
Epoch: 60, Training Loss: 0.0107, Train MSE: 0.0107, r (train): 0.9386, Test MSE: 0.0911, r (test): 0.1211
Epoch: 61, Training Loss: 0.0436, Train MSE: 0.0436, r (train): 0.9441, Test MSE: 0.1450, r (test): 0.0303
Epoch: 62, Training Loss: 0.0678, Train MSE: 0.0678, r (train): 0.9203, Test MSE: 0.1600, r (test): 0.0745
Epoch: 63, Training Loss: 0.0161, Train MSE: 0.0161, r (train): 0.9396, Test MSE: 0.1051, r (test): 0.0308
Epoch: 64, Training Loss: 0.0233, Train MSE: 0.0233, r (train): 0.9454, Test MSE: 0.1180, r (test): 0.1619
Epoch: 65, Training Loss: 0.0344, Train MSE: 0.0344, r (train): 0.9493, Test MSE: 0.1209, r (test): 0.1107
Epoch: 66, Training Loss: 0.0235, Train MSE: 0.0235, r (train): 0.9405, Test MSE: 0.1007, r (test): 0.1309
Epoch: 67, Training Loss: 0.0111, Train MSE: 0.0111, r (train): 0.9382, Test MSE: 0.0832, r (test): 0.0570
Epoch: 68, Training Loss: 0.0300, Train MSE: 0.0300, r (train): 0.9416, Test MSE: 0.0960, r (test): 0.0863
Epoch: 69, Training Loss: 0.0212, Train MSE: 0.0212, r (train): 0.9451, Test MSE: 0.1033, r (test): -0.0165
Epoch: 70, Training Loss: 0.0117, Train MSE: 0.0117, r (train): 0.9474, Test MSE: 0.0949, r (test): -0.0154
Epoch: 71, Training Loss: 0.0263, Train MSE: 0.0263, r (train): 0.9250, Test MSE: 0.0971, r (test): -0.1242
Epoch: 72, Training Loss: 0.0292, Train MSE: 0.0292, r (train): 0.9226, Test MSE: 0.0888, r (test): -0.0232
Epoch: 73, Training Loss: 0.0164, Train MSE: 0.0164, r (train): 0.9112, Test MSE: 0.0856, r (test): -0.0443
Epoch: 74, Training Loss: 0.0065, Train MSE: 0.0065, r (train): 0.9549, Test MSE: 0.0956, r (test): -0.0036
Epoch: 75, Training Loss: 0.0189, Train MSE: 0.0189, r (train): 0.9701, Test MSE: 0.1184, r (test): 0.0563
Epoch: 76, Training Loss: 0.0312, Train MSE: 0.0312, r (train): 0.9468, Test MSE: 0.1165, r (test): 0.1067
Epoch: 77, Training Loss: 0.0075, Train MSE: 0.0075, r (train): 0.9727, Test MSE: 0.0959, r (test): 0.0481
Epoch: 78, Training Loss: 0.0089, Train MSE: 0.0089, r (train): 0.9693, Test MSE: 0.0950, r (test): 0.1521
Epoch: 79, Training Loss: 0.0105, Train MSE: 0.0105, r (train): 0.9664, Test MSE: 0.0854, r (test): 0.1721
Epoch: 80, Training Loss: 0.0152, Train MSE: 0.0152, r (train): 0.9475, Test MSE: 0.0798, r (test): 0.1645
Epoch: 81, Training Loss: 0.0385, Train MSE: 0.0385, r (train): 0.9357, Test MSE: 0.0956, r (test): 0.0138
Epoch: 82, Training Loss: 0.0360, Train MSE: 0.0360, r (train): 0.9572, Test MSE: 0.0963, r (test): 0.0803
Epoch: 83, Training Loss: 0.0213, Train MSE: 0.0213, r (train): 0.9442, Test MSE: 0.0838, r (test): 0.0370
Epoch: 84, Training Loss: 0.0146, Train MSE: 0.0146, r (train): 0.9267, Test MSE: 0.0748, r (test): 0.0890
Epoch: 85, Training Loss: 0.0132, Train MSE: 0.0132, r (train): 0.9304, Test MSE: 0.0879, r (test): 0.1029
Epoch: 86, Training Loss: 0.0304, Train MSE: 0.0304, r (train): 0.9541, Test MSE: 0.1168, r (test): 0.1343
Epoch: 87, Training Loss: 0.0498, Train MSE: 0.0498, r (train): 0.9451, Test MSE: 0.1308, r (test): 0.0650
Epoch: 88, Training Loss: 0.0103, Train MSE: 0.0103, r (train): 0.9467, Test MSE: 0.0891, r (test): 0.1197
Epoch: 89, Training Loss: 0.0139, Train MSE: 0.0139, r (train): 0.9382, Test MSE: 0.1033, r (test): 0.1424
Epoch: 90, Training Loss: 0.0081, Train MSE: 0.0081, r (train): 0.9602, Test MSE: 0.0840, r (test): -0.0640
Epoch: 91, Training Loss: 0.0199, Train MSE: 0.0199, r (train): 0.9298, Test MSE: 0.0859, r (test): -0.0261
Epoch: 92, Training Loss: 0.0296, Train MSE: 0.0296, r (train): 0.9523, Test MSE: 0.0958, r (test): -0.0870
Epoch: 93, Training Loss: 0.0098, Train MSE: 0.0098, r (train): 0.9586, Test MSE: 0.0855, r (test): -0.0495
Epoch: 94, Training Loss: 0.0073, Train MSE: 0.0073, r (train): 0.9504, Test MSE: 0.0881, r (test): -0.0866
Epoch: 95, Training Loss: 0.0174, Train MSE: 0.0174, r (train): 0.9509, Test MSE: 0.1080, r (test): -0.0468
Epoch: 96, Training Loss: 0.0218, Train MSE: 0.0218, r (train): 0.9511, Test MSE: 0.1167, r (test): -0.0034
Epoch: 97, Training Loss: 0.0083, Train MSE: 0.0083, r (train): 0.9612, Test MSE: 0.0917, r (test): 0.0072
Epoch: 98, Training Loss: 0.0110, Train MSE: 0.0110, r (train): 0.9490, Test MSE: 0.0708, r (test): 0.1629
Epoch: 99, Training Loss: 0.0337, Train MSE: 0.0337, r (train): 0.9494, Test MSE: 0.0917, r (test): 0.0059
Predicted tensors for training set: 
tensor([ 0.8462,  0.0685,  0.6118,  0.4363,  0.6195,  0.2803,  0.1542,  0.3999,
         0.3458,  0.2453, -0.1199,  0.5716,  0.4870,  0.3402,  0.4551,  0.4660,
         0.2077, -0.1650,  0.1146,  0.3402,  0.6056,  0.5760,  0.3636,  0.1500,
         0.7578,  0.5502,  0.6634,  0.4108,  0.7620,  0.5073,  0.3515,  0.6712,
         0.7877,  0.7388,  0.1146,  0.6966,  0.7116,  0.2908,  0.0035, -0.0572,
         0.1015,  0.0071,  0.4475,  0.2029,  0.1334,  0.3296, -0.0665,  0.0555,
         0.3808,  0.2196,  0.4228,  0.2982,  0.4422,  0.7090,  0.3555,  0.3107,
         0.6232,  0.5918,  0.3761,  0.7340,  0.4444,  0.6202,  0.0081,  0.6578,
         0.7989,  0.4498,  0.3820,  0.0618,  0.7353,  0.5076,  0.8283,  0.2615])
Target tensorsfor training set: 
tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453])
Correlation for training set: 0.9494329609255887
Predicted tensors for test set: 
tensor([0.2847, 0.0870, 0.3655, 0.3081, 0.3246, 0.4067, 0.2893, 0.4461, 0.3010,
        0.4145, 0.3105, 0.4153, 0.4556, 0.3291, 0.5886, 0.4468, 0.4075, 0.3382])
Target tensors for test set: 
tensor([0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270])
Correlation for test set: 0.005893367751205624
Fold 5
Epoch: 00, Training Loss: 0.0609, Train MSE: 0.0609, r (train): 0.4450, Test MSE: 0.0692, r (test): 0.0182
Epoch: 01, Training Loss: 0.1385, Train MSE: 0.1385, r (train): -0.0211, Test MSE: 0.0799, r (test): 0.0474
Epoch: 02, Training Loss: 0.1004, Train MSE: 0.1004, r (train): 0.2288, Test MSE: 0.0821, r (test): -0.0396
Epoch: 03, Training Loss: 0.0672, Train MSE: 0.0672, r (train): 0.4152, Test MSE: 0.0872, r (test): 0.0801
Epoch: 04, Training Loss: 0.0590, Train MSE: 0.0590, r (train): 0.4929, Test MSE: 0.0777, r (test): 0.1496
Epoch: 05, Training Loss: 0.0584, Train MSE: 0.0584, r (train): 0.4900, Test MSE: 0.0720, r (test): 0.2146
Epoch: 06, Training Loss: 0.0697, Train MSE: 0.0697, r (train): 0.4326, Test MSE: 0.0759, r (test): 0.1317
Epoch: 07, Training Loss: 0.0592, Train MSE: 0.0592, r (train): 0.4687, Test MSE: 0.0798, r (test): 0.1329
Epoch: 08, Training Loss: 0.0653, Train MSE: 0.0653, r (train): 0.3372, Test MSE: 0.0718, r (test): 0.1454
Epoch: 09, Training Loss: 0.0571, Train MSE: 0.0571, r (train): 0.5013, Test MSE: 0.0710, r (test): 0.2560
Epoch: 10, Training Loss: 0.0848, Train MSE: 0.0848, r (train): 0.4220, Test MSE: 0.0935, r (test): 0.0792
Epoch: 11, Training Loss: 0.0738, Train MSE: 0.0738, r (train): 0.4458, Test MSE: 0.0935, r (test): 0.0764
Epoch: 12, Training Loss: 0.0601, Train MSE: 0.0601, r (train): 0.4371, Test MSE: 0.0745, r (test): 0.2491
Epoch: 13, Training Loss: 0.0647, Train MSE: 0.0647, r (train): 0.3645, Test MSE: 0.0745, r (test): 0.1207
Epoch: 14, Training Loss: 0.0739, Train MSE: 0.0739, r (train): 0.4420, Test MSE: 0.0802, r (test): 0.1373
Epoch: 15, Training Loss: 0.0616, Train MSE: 0.0616, r (train): 0.5021, Test MSE: 0.0860, r (test): 0.1081
Epoch: 16, Training Loss: 0.0589, Train MSE: 0.0589, r (train): 0.4533, Test MSE: 0.0738, r (test): 0.2886
Epoch: 17, Training Loss: 0.0496, Train MSE: 0.0496, r (train): 0.6429, Test MSE: 0.0753, r (test): 0.2644
Epoch: 18, Training Loss: 0.0625, Train MSE: 0.0625, r (train): 0.5250, Test MSE: 0.0849, r (test): 0.1345
Epoch: 19, Training Loss: 0.0451, Train MSE: 0.0451, r (train): 0.6641, Test MSE: 0.0747, r (test): 0.2474
Epoch: 20, Training Loss: 0.0525, Train MSE: 0.0525, r (train): 0.5527, Test MSE: 0.0720, r (test): 0.3524
Epoch: 21, Training Loss: 0.0728, Train MSE: 0.0728, r (train): 0.4805, Test MSE: 0.0773, r (test): 0.1060
Epoch: 22, Training Loss: 0.0672, Train MSE: 0.0672, r (train): 0.3675, Test MSE: 0.0729, r (test): 0.2512
Epoch: 23, Training Loss: 0.0727, Train MSE: 0.0727, r (train): 0.5033, Test MSE: 0.0780, r (test): 0.1769
Epoch: 24, Training Loss: 0.0438, Train MSE: 0.0438, r (train): 0.7434, Test MSE: 0.0715, r (test): 0.4296
Epoch: 25, Training Loss: 0.0321, Train MSE: 0.0321, r (train): 0.8158, Test MSE: 0.0724, r (test): 0.2811
Epoch: 26, Training Loss: 0.0286, Train MSE: 0.0286, r (train): 0.8483, Test MSE: 0.0734, r (test): 0.3141
Epoch: 27, Training Loss: 0.0219, Train MSE: 0.0219, r (train): 0.8868, Test MSE: 0.0699, r (test): 0.3101
Epoch: 28, Training Loss: 0.0171, Train MSE: 0.0171, r (train): 0.9164, Test MSE: 0.0698, r (test): 0.3296
Epoch: 29, Training Loss: 0.0140, Train MSE: 0.0140, r (train): 0.9325, Test MSE: 0.0717, r (test): 0.3101
Epoch: 30, Training Loss: 0.0096, Train MSE: 0.0096, r (train): 0.9503, Test MSE: 0.0666, r (test): 0.3856
Epoch: 31, Training Loss: 0.0069, Train MSE: 0.0069, r (train): 0.9586, Test MSE: 0.0701, r (test): 0.2878
Epoch: 32, Training Loss: 0.0091, Train MSE: 0.0091, r (train): 0.9466, Test MSE: 0.0568, r (test): 0.3952
Epoch: 33, Training Loss: 0.0135, Train MSE: 0.0135, r (train): 0.9420, Test MSE: 0.0774, r (test): 0.3685
Epoch: 34, Training Loss: 0.0122, Train MSE: 0.0122, r (train): 0.9667, Test MSE: 0.0578, r (test): 0.3703
Epoch: 35, Training Loss: 0.0053, Train MSE: 0.0053, r (train): 0.9659, Test MSE: 0.0705, r (test): 0.2122
Epoch: 36, Training Loss: 0.0101, Train MSE: 0.0101, r (train): 0.9583, Test MSE: 0.0605, r (test): 0.3230
Epoch: 37, Training Loss: 0.0061, Train MSE: 0.0061, r (train): 0.9682, Test MSE: 0.0727, r (test): 0.0362
Epoch: 38, Training Loss: 0.0056, Train MSE: 0.0056, r (train): 0.9678, Test MSE: 0.0753, r (test): 0.1411
Epoch: 39, Training Loss: 0.0184, Train MSE: 0.0184, r (train): 0.9383, Test MSE: 0.0890, r (test): 0.0620
Epoch: 40, Training Loss: 0.0299, Train MSE: 0.0299, r (train): 0.9329, Test MSE: 0.1088, r (test): 0.2032
Epoch: 41, Training Loss: 0.0107, Train MSE: 0.0107, r (train): 0.9387, Test MSE: 0.0700, r (test): 0.2722
Epoch: 42, Training Loss: 0.0109, Train MSE: 0.0109, r (train): 0.9449, Test MSE: 0.0582, r (test): 0.3609
Epoch: 43, Training Loss: 0.0413, Train MSE: 0.0413, r (train): 0.9475, Test MSE: 0.0886, r (test): 0.0776
Epoch: 44, Training Loss: 0.0065, Train MSE: 0.0065, r (train): 0.9597, Test MSE: 0.0646, r (test): 0.2498
Epoch: 45, Training Loss: 0.0042, Train MSE: 0.0042, r (train): 0.9717, Test MSE: 0.0765, r (test): 0.0580
Epoch: 46, Training Loss: 0.0038, Train MSE: 0.0038, r (train): 0.9770, Test MSE: 0.0693, r (test): 0.1405
Epoch: 47, Training Loss: 0.0151, Train MSE: 0.0151, r (train): 0.9622, Test MSE: 0.0768, r (test): 0.0725
Epoch: 48, Training Loss: 0.0159, Train MSE: 0.0159, r (train): 0.9671, Test MSE: 0.0729, r (test): 0.0649
Epoch: 49, Training Loss: 0.0053, Train MSE: 0.0053, r (train): 0.9720, Test MSE: 0.0733, r (test): 0.0914
Epoch: 50, Training Loss: 0.0062, Train MSE: 0.0062, r (train): 0.9716, Test MSE: 0.0758, r (test): 0.1933
Epoch: 51, Training Loss: 0.0098, Train MSE: 0.0098, r (train): 0.9629, Test MSE: 0.0804, r (test): 0.1884
Epoch: 52, Training Loss: 0.0101, Train MSE: 0.0101, r (train): 0.9507, Test MSE: 0.0688, r (test): 0.2604
Epoch: 53, Training Loss: 0.0078, Train MSE: 0.0078, r (train): 0.9501, Test MSE: 0.0771, r (test): 0.1420
Epoch: 54, Training Loss: 0.0110, Train MSE: 0.0110, r (train): 0.9467, Test MSE: 0.0833, r (test): 0.1862
Epoch: 55, Training Loss: 0.0096, Train MSE: 0.0096, r (train): 0.9562, Test MSE: 0.0788, r (test): 0.1886
Epoch: 56, Training Loss: 0.0295, Train MSE: 0.0295, r (train): 0.9582, Test MSE: 0.0998, r (test): 0.1548
Epoch: 57, Training Loss: 0.0493, Train MSE: 0.0493, r (train): 0.9301, Test MSE: 0.1380, r (test): 0.2715
Epoch: 58, Training Loss: 0.0454, Train MSE: 0.0454, r (train): 0.9632, Test MSE: 0.1233, r (test): 0.2803
Epoch: 59, Training Loss: 0.0301, Train MSE: 0.0301, r (train): 0.9376, Test MSE: 0.0918, r (test): 0.3644
Epoch: 60, Training Loss: 0.0097, Train MSE: 0.0097, r (train): 0.9451, Test MSE: 0.0728, r (test): 0.2827
Epoch: 61, Training Loss: 0.0113, Train MSE: 0.0113, r (train): 0.9373, Test MSE: 0.0733, r (test): 0.1656
Epoch: 62, Training Loss: 0.0117, Train MSE: 0.0117, r (train): 0.9292, Test MSE: 0.0686, r (test): 0.1679
Epoch: 63, Training Loss: 0.0121, Train MSE: 0.0121, r (train): 0.9166, Test MSE: 0.0734, r (test): 0.1005
Epoch: 64, Training Loss: 0.0101, Train MSE: 0.0101, r (train): 0.9348, Test MSE: 0.0774, r (test): 0.1581
Epoch: 65, Training Loss: 0.0092, Train MSE: 0.0092, r (train): 0.9451, Test MSE: 0.0610, r (test): 0.3265
Epoch: 66, Training Loss: 0.0086, Train MSE: 0.0086, r (train): 0.9607, Test MSE: 0.0720, r (test): 0.1598
Epoch: 67, Training Loss: 0.0174, Train MSE: 0.0174, r (train): 0.9699, Test MSE: 0.0689, r (test): 0.1843
Epoch: 68, Training Loss: 0.0159, Train MSE: 0.0159, r (train): 0.9603, Test MSE: 0.0749, r (test): 0.1344
Epoch: 69, Training Loss: 0.0093, Train MSE: 0.0093, r (train): 0.9489, Test MSE: 0.0760, r (test): 0.1527
Epoch: 70, Training Loss: 0.0106, Train MSE: 0.0106, r (train): 0.9384, Test MSE: 0.0810, r (test): 0.1502
Epoch: 71, Training Loss: 0.0157, Train MSE: 0.0157, r (train): 0.9398, Test MSE: 0.0874, r (test): 0.2050
Epoch: 72, Training Loss: 0.0353, Train MSE: 0.0353, r (train): 0.9014, Test MSE: 0.1081, r (test): 0.2960
Epoch: 73, Training Loss: 0.0489, Train MSE: 0.0489, r (train): 0.8840, Test MSE: 0.1312, r (test): 0.2973
Epoch: 74, Training Loss: 0.0729, Train MSE: 0.0729, r (train): 0.8718, Test MSE: 0.1550, r (test): 0.3551
Epoch: 75, Training Loss: 0.0554, Train MSE: 0.0554, r (train): 0.8857, Test MSE: 0.1174, r (test): 0.4061
Epoch: 76, Training Loss: 0.0269, Train MSE: 0.0269, r (train): 0.8391, Test MSE: 0.1016, r (test): -0.0182
Epoch: 77, Training Loss: 0.0219, Train MSE: 0.0219, r (train): 0.8636, Test MSE: 0.0949, r (test): -0.1088
Epoch: 78, Training Loss: 0.0112, Train MSE: 0.0112, r (train): 0.9376, Test MSE: 0.0775, r (test): -0.0523
Epoch: 79, Training Loss: 0.0179, Train MSE: 0.0179, r (train): 0.9262, Test MSE: 0.0694, r (test): 0.1141
Epoch: 80, Training Loss: 0.0144, Train MSE: 0.0144, r (train): 0.9213, Test MSE: 0.0727, r (test): 0.0553
Epoch: 81, Training Loss: 0.0127, Train MSE: 0.0127, r (train): 0.9495, Test MSE: 0.0675, r (test): 0.1348
Epoch: 82, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.9345, Test MSE: 0.0717, r (test): 0.0699
Epoch: 83, Training Loss: 0.0097, Train MSE: 0.0097, r (train): 0.9400, Test MSE: 0.0800, r (test): 0.0528
Epoch: 84, Training Loss: 0.0206, Train MSE: 0.0206, r (train): 0.9612, Test MSE: 0.1082, r (test): 0.1162
Epoch: 85, Training Loss: 0.0389, Train MSE: 0.0389, r (train): 0.9601, Test MSE: 0.1413, r (test): 0.0612
Epoch: 86, Training Loss: 0.0168, Train MSE: 0.0168, r (train): 0.9581, Test MSE: 0.0989, r (test): -0.0694
Epoch: 87, Training Loss: 0.0100, Train MSE: 0.0100, r (train): 0.9326, Test MSE: 0.0816, r (test): -0.0107
Epoch: 88, Training Loss: 0.0077, Train MSE: 0.0077, r (train): 0.9538, Test MSE: 0.0851, r (test): -0.0927
Epoch: 89, Training Loss: 0.0097, Train MSE: 0.0097, r (train): 0.9564, Test MSE: 0.0778, r (test): -0.0599
Epoch: 90, Training Loss: 0.0062, Train MSE: 0.0062, r (train): 0.9607, Test MSE: 0.0796, r (test): -0.1168
Epoch: 91, Training Loss: 0.0129, Train MSE: 0.0129, r (train): 0.9472, Test MSE: 0.0904, r (test): 0.0921
Epoch: 92, Training Loss: 0.0278, Train MSE: 0.0278, r (train): 0.9450, Test MSE: 0.1132, r (test): 0.1380
Epoch: 93, Training Loss: 0.0313, Train MSE: 0.0313, r (train): 0.9519, Test MSE: 0.1153, r (test): 0.1210
Epoch: 94, Training Loss: 0.0241, Train MSE: 0.0241, r (train): 0.9294, Test MSE: 0.1092, r (test): -0.0822
Epoch: 95, Training Loss: 0.0121, Train MSE: 0.0121, r (train): 0.9169, Test MSE: 0.0921, r (test): -0.1629
Epoch: 96, Training Loss: 0.0098, Train MSE: 0.0098, r (train): 0.9511, Test MSE: 0.0912, r (test): -0.3153
Epoch: 97, Training Loss: 0.0114, Train MSE: 0.0114, r (train): 0.9392, Test MSE: 0.0824, r (test): -0.1143
Epoch: 98, Training Loss: 0.0143, Train MSE: 0.0143, r (train): 0.9453, Test MSE: 0.0965, r (test): 0.0336
Epoch: 99, Training Loss: 0.0461, Train MSE: 0.0461, r (train): 0.8975, Test MSE: 0.1479, r (test): 0.0672
Predicted tensors for training set: 
tensor([ 5.9710e-01, -3.0848e-01,  6.5804e-01,  5.8412e-01,  6.2385e-01,
         2.3085e-01,  1.8508e-01,  4.5332e-01,  3.5490e-01,  2.1753e-02,
        -1.2452e-01,  5.9661e-01,  6.4333e-01,  4.1268e-01,  5.5370e-01,
         7.2002e-01,  2.3718e-01, -1.1012e-01,  1.4165e-01,  3.7191e-01,
         8.1675e-01,  7.7203e-01,  4.6450e-01,  1.5274e-01,  9.2976e-01,
         6.0272e-01,  6.6262e-01,  4.9708e-01,  8.5612e-01,  5.7612e-01,
         3.9131e-01,  6.5920e-01,  8.3131e-01,  7.3308e-01,  9.1331e-02,
         7.3962e-01,  6.6271e-01,  3.1826e-01, -1.2045e-01, -4.2586e-01,
         2.5730e-02, -8.1851e-02,  4.0972e-01,  4.7079e-03,  8.2448e-02,
         2.9141e-01, -6.0994e-01, -6.1245e-04,  4.6084e-01,  5.5971e-02,
         3.7488e-01,  2.0038e-01,  4.9687e-01,  7.1987e-01,  5.6239e-01,
        -1.7801e-01,  3.8779e-01,  1.8413e-01,  7.6539e-01,  8.1659e-01,
         6.6086e-02,  2.1845e-01,  5.0434e-01,  5.8324e-01,  7.4934e-01,
         4.8592e-01,  7.8610e-01,  7.2449e-01,  1.8429e-01,  3.3758e-01,
         2.9028e-01,  6.9367e-01])
Target tensorsfor training set: 
tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270])
Correlation for training set: 0.8975010768080924
Predicted tensors for test set: 
tensor([ 0.5557,  0.2711,  0.5382,  0.4704,  0.3054,  0.2696, -0.0093,  0.3880,
         0.3341,  0.2969,  0.4435, -0.1565,  0.4711,  0.4864,  0.3716,  0.4287,
         0.4171,  0.4140])
Target tensors for test set: 
tensor([0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453])
Correlation for test set: 0.06721594886136849
Seed: 65
Fold losses: [tensor(0.0100), tensor(0.0221), tensor(0.0452), tensor(0.0337), tensor(0.0461)]
Fold MSE values: [tensor(0.0100), tensor(0.0221), tensor(0.0452), tensor(0.0337), tensor(0.0461)]
Target training values: [tensor([0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453]), tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453]), tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453]), tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.5187, 0.5023, 0.7950, 0.8411, 0.4149, 0.9150, 0.6199, 0.6992, 0.0389,
        0.7596, 0.8524, 0.4526, 0.4654, 0.0636, 0.7462, 0.5783, 0.9621, 0.3453]), tensor([0.8988, 0.1218, 0.7507, 0.6671, 0.8453, 0.5779, 0.2464, 0.5719, 0.5564,
        0.4513, 0.0478, 0.7791, 0.8391, 0.5658, 0.7372, 0.8556, 0.3309, 0.0246,
        0.2169, 0.4818, 0.9127, 0.9072, 0.5300, 0.2649, 0.9656, 0.6595, 0.7144,
        0.4993, 0.9215, 0.6465, 0.4640, 0.7901, 0.9492, 0.8418, 0.1493, 0.9117,
        0.8561, 0.4373, 0.0981, 0.1055, 0.2916, 0.1295, 0.6846, 0.4036, 0.3174,
        0.5780, 0.2255, 0.2594, 0.6240, 0.5220, 0.6577, 0.4341, 0.6576, 0.9535,
        0.7125, 0.1360, 0.5102, 0.2394, 0.8363, 0.8728, 0.0763, 0.2271, 0.5178,
        0.5573, 0.7497, 0.4440, 0.7371, 0.7171, 0.1294, 0.3829, 0.3077, 0.7270])]
Prediction training values: [tensor([ 0.2375,  0.5249,  0.9305,  0.9625,  0.5500,  0.2937,  0.8885,  0.6264,
         0.7863,  0.4986,  0.9032,  0.6644,  0.5643,  0.8330,  0.9664,  0.8826,
         0.2117,  0.8370,  0.8450,  0.4249,  0.1200, -0.0202,  0.2740,  0.1389,
         0.6805,  0.3228,  0.2328,  0.4690, -0.0150,  0.1350,  0.4976,  0.3619,
         0.5537,  0.3307,  0.5859,  0.8330,  0.5756, -0.0136,  0.4264,  0.2394,
         0.6895,  0.7083,  0.1349,  0.2630,  0.3723,  0.4584,  0.6984,  0.4979,
         0.7510,  0.7308,  0.1884,  0.5269,  0.4547,  0.8484,  0.5906,  0.5752,
         1.0073,  0.9947,  0.5488,  1.1632,  0.7093,  0.8751,  0.2184,  0.8806,
         0.9712,  0.5334,  0.5119,  0.1253,  0.7727,  0.5962,  0.9729,  0.4425]), tensor([ 7.6411e-01, -1.4158e-01,  6.0914e-01,  5.6019e-01,  6.7161e-01,
         3.2975e-01,  1.0735e-01,  3.6606e-01,  2.6172e-01,  1.7390e-01,
        -2.1411e-01,  5.7062e-01,  5.9258e-01,  2.9186e-01,  5.5745e-01,
         6.0842e-01,  6.9115e-02, -2.3075e-01,  6.7634e-01,  2.1478e-01,
        -4.5387e-02, -9.0876e-02,  1.2544e-01, -2.5121e-02,  6.1238e-01,
         3.3745e-01,  2.4520e-01,  4.8928e-01,  1.4402e-01,  1.2092e-01,
         5.4310e-01,  4.2012e-01,  5.6247e-01,  3.5046e-01,  5.7199e-01,
         8.3523e-01,  6.0263e-01,  2.1621e-02,  4.0907e-01,  1.1564e-01,
         7.1049e-01,  6.0747e-01, -8.9500e-02,  2.3099e-02,  3.8269e-01,
         4.2121e-01,  6.1869e-01,  3.0895e-01,  6.0375e-01,  5.6366e-01,
        -2.3659e-04,  3.2654e-01,  2.2259e-01,  6.5616e-01,  4.5687e-01,
         4.7676e-01,  7.8746e-01,  8.4222e-01,  4.0120e-01,  9.3196e-01,
         5.5813e-01,  6.9640e-01,  2.8694e-02,  7.3832e-01,  8.6167e-01,
         3.9428e-01,  4.2734e-01,  7.7411e-02,  7.5924e-01,  5.6022e-01,
         8.6832e-01,  2.3768e-01]), tensor([ 0.7689,  0.0711,  0.6096,  0.4930,  0.6941,  0.4159,  0.1466,  0.3927,
         0.1716,  0.1895, -0.1993,  0.5268,  0.5049,  0.3363,  0.4711,  0.5551,
         0.2455,  0.0126,  0.1482,  0.3528,  0.6593,  0.6822,  0.3337,  0.1235,
         0.7300,  0.5236,  0.4888,  0.3106,  0.7296,  0.4545,  0.3599,  0.6498,
         0.8206,  0.6248,  0.1123,  0.8223,  0.6050,  0.0863,  0.3628,  0.0680,
         0.6918,  0.6486, -0.0873,  0.1152,  0.3199,  0.3890,  0.4935,  0.2349,
         0.5110,  0.2926, -0.1840,  0.0899,  0.0415,  0.4219,  0.0829,  0.2800,
         0.4460,  0.3606,  0.3084,  0.5700,  0.3526,  0.4567, -0.0560,  0.6174,
         0.6966,  0.3366,  0.3729,  0.0524,  0.7023,  0.4980,  0.8312,  0.2961]), tensor([ 0.8462,  0.0685,  0.6118,  0.4363,  0.6195,  0.2803,  0.1542,  0.3999,
         0.3458,  0.2453, -0.1199,  0.5716,  0.4870,  0.3402,  0.4551,  0.4660,
         0.2077, -0.1650,  0.1146,  0.3402,  0.6056,  0.5760,  0.3636,  0.1500,
         0.7578,  0.5502,  0.6634,  0.4108,  0.7620,  0.5073,  0.3515,  0.6712,
         0.7877,  0.7388,  0.1146,  0.6966,  0.7116,  0.2908,  0.0035, -0.0572,
         0.1015,  0.0071,  0.4475,  0.2029,  0.1334,  0.3296, -0.0665,  0.0555,
         0.3808,  0.2196,  0.4228,  0.2982,  0.4422,  0.7090,  0.3555,  0.3107,
         0.6232,  0.5918,  0.3761,  0.7340,  0.4444,  0.6202,  0.0081,  0.6578,
         0.7989,  0.4498,  0.3820,  0.0618,  0.7353,  0.5076,  0.8283,  0.2615]), tensor([ 5.9710e-01, -3.0848e-01,  6.5804e-01,  5.8412e-01,  6.2385e-01,
         2.3085e-01,  1.8508e-01,  4.5332e-01,  3.5490e-01,  2.1753e-02,
        -1.2452e-01,  5.9661e-01,  6.4333e-01,  4.1268e-01,  5.5370e-01,
         7.2002e-01,  2.3718e-01, -1.1012e-01,  1.4165e-01,  3.7191e-01,
         8.1675e-01,  7.7203e-01,  4.6450e-01,  1.5274e-01,  9.2976e-01,
         6.0272e-01,  6.6262e-01,  4.9708e-01,  8.5612e-01,  5.7612e-01,
         3.9131e-01,  6.5920e-01,  8.3131e-01,  7.3308e-01,  9.1331e-02,
         7.3962e-01,  6.6271e-01,  3.1826e-01, -1.2045e-01, -4.2586e-01,
         2.5730e-02, -8.1851e-02,  4.0972e-01,  4.7079e-03,  8.2448e-02,
         2.9141e-01, -6.0994e-01, -6.1245e-04,  4.6084e-01,  5.5971e-02,
         3.7488e-01,  2.0038e-01,  4.9687e-01,  7.1987e-01,  5.6239e-01,
        -1.7801e-01,  3.8779e-01,  1.8413e-01,  7.6539e-01,  8.1659e-01,
         6.6086e-02,  2.1845e-01,  5.0434e-01,  5.8324e-01,  7.4934e-01,
         4.8592e-01,  7.8610e-01,  7.2449e-01,  1.8429e-01,  3.3758e-01,
         2.9028e-01,  6.9367e-01])]
Target values: [array([0.89876264, 0.12180944, 0.75073236, 0.6671056 , 0.84525365,
       0.5778506 , 0.24636388, 0.57190746, 0.55641776, 0.45128736,
       0.04781396, 0.77910316, 0.8390776 , 0.5658469 , 0.73719215,
       0.85557973, 0.33092642, 0.02463444], dtype=float32), array([0.21692123, 0.48182514, 0.912732  , 0.9071598 , 0.52996147,
       0.2649091 , 0.96564525, 0.659493  , 0.71435624, 0.4993471 ,
       0.9215425 , 0.6464906 , 0.46398443, 0.7900961 , 0.9491663 ,
       0.8417677 , 0.14931566, 0.9116711 ], dtype=float32), array([0.85610735, 0.4372734 , 0.09805249, 0.10552448, 0.29163042,
       0.12948532, 0.6846425 , 0.40355092, 0.31742746, 0.578045  ,
       0.2254639 , 0.25936916, 0.62399   , 0.5220161 , 0.65769196,
       0.43409458, 0.6576234 , 0.95346546], dtype=float32), array([0.71252435, 0.1360485 , 0.51015127, 0.23939352, 0.83626515,
       0.8728059 , 0.07633217, 0.22711647, 0.51780254, 0.55726975,
       0.7497406 , 0.44401234, 0.73709923, 0.71714455, 0.12937951,
       0.38285765, 0.30766785, 0.72703534], dtype=float32), array([0.518717  , 0.50225437, 0.79497874, 0.84113044, 0.41493568,
       0.91498566, 0.6198749 , 0.69921327, 0.03887437, 0.75962484,
       0.8524316 , 0.45263878, 0.46544507, 0.06358391, 0.7462256 ,
       0.57832706, 0.96213573, 0.34531343], dtype=float32)]
Prediction values: [array([-0.03436   , -0.40822086,  0.44735625,  0.49109828,  0.42020595,
        0.7091573 ,  0.5917994 ,  0.46708924,  0.519653  ,  0.49500546,
        0.63768077,  0.40759823,  0.5620354 ,  0.37552202,  0.62641853,
        0.53186893,  0.4610046 ,  0.7947517 ], dtype=float32), array([0.4245431 , 0.3343312 , 0.7371224 , 0.4159338 , 0.42254868,
       0.46217608, 0.619578  , 0.44749445, 0.33242488, 0.27585962,
       0.35997912, 0.34072226, 0.503017  , 0.36353114, 0.41823775,
       0.39686972, 0.6874269 , 0.3942191 ], dtype=float32), array([0.3113661 , 0.37283972, 0.44329107, 0.09246983, 0.41033307,
       0.36722472, 0.37413284, 0.38344514, 0.30502415, 0.46313795,
       0.37006688, 0.28728768, 0.45966882, 0.30561152, 0.51219296,
       0.30899584, 0.2656001 , 0.5064469 ], dtype=float32), array([0.28466636, 0.08697744, 0.36550742, 0.30809218, 0.3245711 ,
       0.4066797 , 0.2892987 , 0.44607437, 0.30095983, 0.4145008 ,
       0.3104553 , 0.41531304, 0.45562938, 0.32906237, 0.5886422 ,
       0.44678545, 0.40745515, 0.33817917], dtype=float32), array([ 0.55567026,  0.2711055 ,  0.53816605,  0.47038487,  0.30543143,
        0.2695628 , -0.0092923 ,  0.38797614,  0.3340818 ,  0.2968538 ,
        0.4435318 , -0.15652126,  0.47105947,  0.48642483,  0.37158233,
        0.42874914,  0.41710192,  0.41398582], dtype=float32)]
Time taken: 1090.0808877944946 seconds
