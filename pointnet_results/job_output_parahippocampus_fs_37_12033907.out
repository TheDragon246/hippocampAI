sh: line 1: logger: command not found
/apps/conda/25.3.1/etc/profile.d/conda.sh: line 69: dirname: command not found
/apps/conda/25.3.1/etc/profile.d/conda.sh: line 69: dirname: command not found
/apps/conda/25.3.1/etc/profile.d/mamba.sh: line 59: basename: command not found
Error unknown MAMBA_EXE: "/apps/conda/25.3.1/bin/mamba", filename must be mamba or micromamba
Lmod has detected the following error: This module can only be used on RHEL9 nodes. 
While processing the following module(s):
    Module fullname  Module Filename
    ---------------  ---------------
    gcc/14.2.0       /apps/lmod/modulefiles/core/gcc/14.2.0.lua

pointnet_parahippocampus_fs_37.py
/blue/stevenweisberg/ashishkumarsahoo/hippocampAI/conda_pyg_070923/lib/python3.8/site-packages/torch/cuda/__init__.py:155: UserWarning: 
NVIDIA B200 with CUDA capability sm_100 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 compute_37.
If you want to use the NVIDIA B200 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
Number of GPUs available for training: 1
Fold 1
Epoch: 00, Training Loss: 0.0904, Train MSE: 0.0904, r (train): 0.2270, Test MSE: 0.0615, r (test): 0.3322
Epoch: 01, Training Loss: 0.0707, Train MSE: 0.0707, r (train): 0.3074, Test MSE: 0.0643, r (test): 0.1466
Epoch: 02, Training Loss: 0.0685, Train MSE: 0.0685, r (train): 0.3942, Test MSE: 0.0783, r (test): 0.0174
Epoch: 03, Training Loss: 0.0691, Train MSE: 0.0691, r (train): 0.4464, Test MSE: 0.0871, r (test): 0.0050
Epoch: 04, Training Loss: 0.0672, Train MSE: 0.0672, r (train): 0.4770, Test MSE: 0.0912, r (test): 0.0210
Epoch: 05, Training Loss: 0.0723, Train MSE: 0.0723, r (train): 0.4861, Test MSE: 0.1067, r (test): 0.0046
Epoch: 06, Training Loss: 0.0682, Train MSE: 0.0682, r (train): 0.5345, Test MSE: 0.1135, r (test): -0.0224
Epoch: 07, Training Loss: 0.0692, Train MSE: 0.0692, r (train): 0.5468, Test MSE: 0.1201, r (test): -0.0223
Epoch: 08, Training Loss: 0.0696, Train MSE: 0.0696, r (train): 0.5660, Test MSE: 0.1323, r (test): -0.0530
Epoch: 09, Training Loss: 0.0671, Train MSE: 0.0671, r (train): 0.5955, Test MSE: 0.1261, r (test): -0.0386
Epoch: 10, Training Loss: 0.0592, Train MSE: 0.0592, r (train): 0.6395, Test MSE: 0.1362, r (test): -0.0832
Epoch: 11, Training Loss: 0.0626, Train MSE: 0.0626, r (train): 0.6388, Test MSE: 0.1260, r (test): -0.0106
Epoch: 12, Training Loss: 0.0468, Train MSE: 0.0468, r (train): 0.6812, Test MSE: 0.1306, r (test): -0.0621
Epoch: 13, Training Loss: 0.0617, Train MSE: 0.0617, r (train): 0.7069, Test MSE: 0.1314, r (test): -0.0122
Epoch: 14, Training Loss: 0.0530, Train MSE: 0.0530, r (train): 0.7219, Test MSE: 0.1465, r (test): -0.0662
Epoch: 15, Training Loss: 0.0479, Train MSE: 0.0479, r (train): 0.7536, Test MSE: 0.1323, r (test): -0.0735
Epoch: 16, Training Loss: 0.0456, Train MSE: 0.0456, r (train): 0.7260, Test MSE: 0.1565, r (test): -0.1008
Epoch: 17, Training Loss: 0.0484, Train MSE: 0.0484, r (train): 0.7614, Test MSE: 0.1317, r (test): -0.0509
Epoch: 18, Training Loss: 0.0386, Train MSE: 0.0386, r (train): 0.7906, Test MSE: 0.1477, r (test): -0.0837
Epoch: 19, Training Loss: 0.0503, Train MSE: 0.0503, r (train): 0.7800, Test MSE: 0.1330, r (test): -0.0264
Epoch: 20, Training Loss: 0.0338, Train MSE: 0.0338, r (train): 0.8321, Test MSE: 0.1414, r (test): -0.0663
Epoch: 21, Training Loss: 0.0344, Train MSE: 0.0344, r (train): 0.8344, Test MSE: 0.1393, r (test): -0.0829
Epoch: 22, Training Loss: 0.0379, Train MSE: 0.0379, r (train): 0.7839, Test MSE: 0.1397, r (test): 0.0056
Epoch: 23, Training Loss: 0.0303, Train MSE: 0.0303, r (train): 0.8161, Test MSE: 0.1403, r (test): -0.0523
Epoch: 24, Training Loss: 0.0390, Train MSE: 0.0390, r (train): 0.7799, Test MSE: 0.1200, r (test): 0.0467
Epoch: 25, Training Loss: 0.0312, Train MSE: 0.0312, r (train): 0.8480, Test MSE: 0.1285, r (test): 0.0146
Epoch: 26, Training Loss: 0.0339, Train MSE: 0.0339, r (train): 0.8250, Test MSE: 0.1272, r (test): 0.0167
Epoch: 27, Training Loss: 0.0257, Train MSE: 0.0257, r (train): 0.8323, Test MSE: 0.1292, r (test): -0.0437
Epoch: 28, Training Loss: 0.0180, Train MSE: 0.0180, r (train): 0.8768, Test MSE: 0.1555, r (test): -0.1437
Epoch: 29, Training Loss: 0.0251, Train MSE: 0.0251, r (train): 0.8351, Test MSE: 0.1457, r (test): -0.0532
Epoch: 30, Training Loss: 0.0225, Train MSE: 0.0225, r (train): 0.8448, Test MSE: 0.1443, r (test): -0.0366
Epoch: 31, Training Loss: 0.0312, Train MSE: 0.0312, r (train): 0.7949, Test MSE: 0.1003, r (test): 0.0628
Epoch: 32, Training Loss: 0.0309, Train MSE: 0.0309, r (train): 0.7844, Test MSE: 0.1088, r (test): 0.0488
Epoch: 33, Training Loss: 0.0243, Train MSE: 0.0243, r (train): 0.8340, Test MSE: 0.1154, r (test): -0.0419
Epoch: 34, Training Loss: 0.0271, Train MSE: 0.0271, r (train): 0.8221, Test MSE: 0.1059, r (test): 0.0395
Epoch: 35, Training Loss: 0.0245, Train MSE: 0.0245, r (train): 0.8396, Test MSE: 0.1355, r (test): -0.0993
Epoch: 36, Training Loss: 0.0186, Train MSE: 0.0186, r (train): 0.8807, Test MSE: 0.1322, r (test): -0.0923
Epoch: 37, Training Loss: 0.0231, Train MSE: 0.0231, r (train): 0.8628, Test MSE: 0.1309, r (test): -0.0860
Epoch: 38, Training Loss: 0.0228, Train MSE: 0.0228, r (train): 0.8637, Test MSE: 0.1250, r (test): -0.0616
Epoch: 39, Training Loss: 0.0304, Train MSE: 0.0304, r (train): 0.8637, Test MSE: 0.1497, r (test): -0.1791
Epoch: 40, Training Loss: 0.0249, Train MSE: 0.0249, r (train): 0.8628, Test MSE: 0.1472, r (test): -0.2203
Epoch: 41, Training Loss: 0.0336, Train MSE: 0.0336, r (train): 0.8566, Test MSE: 0.1730, r (test): -0.3151
Epoch: 42, Training Loss: 0.0221, Train MSE: 0.0221, r (train): 0.8607, Test MSE: 0.1484, r (test): -0.2580
Epoch: 43, Training Loss: 0.0270, Train MSE: 0.0270, r (train): 0.8620, Test MSE: 0.1619, r (test): -0.2521
Epoch: 44, Training Loss: 0.0355, Train MSE: 0.0355, r (train): 0.8448, Test MSE: 0.1703, r (test): -0.2938
Epoch: 45, Training Loss: 0.0381, Train MSE: 0.0381, r (train): 0.8864, Test MSE: 0.1744, r (test): -0.2542
Epoch: 46, Training Loss: 0.0558, Train MSE: 0.0558, r (train): 0.8126, Test MSE: 0.1600, r (test): -0.2911
Epoch: 47, Training Loss: 0.0743, Train MSE: 0.0743, r (train): 0.8467, Test MSE: 0.2070, r (test): -0.3040
Epoch: 48, Training Loss: 0.0602, Train MSE: 0.0602, r (train): 0.8770, Test MSE: 0.2058, r (test): -0.2843
Epoch: 49, Training Loss: 0.0958, Train MSE: 0.0958, r (train): 0.8309, Test MSE: 0.2216, r (test): -0.2838
Epoch: 50, Training Loss: 0.0970, Train MSE: 0.0970, r (train): 0.8822, Test MSE: 0.2329, r (test): -0.3295
Epoch: 51, Training Loss: 0.1384, Train MSE: 0.1384, r (train): 0.8278, Test MSE: 0.2882, r (test): -0.3053
Epoch: 52, Training Loss: 0.1714, Train MSE: 0.1714, r (train): 0.8487, Test MSE: 0.2682, r (test): -0.2195
Epoch: 53, Training Loss: 0.1290, Train MSE: 0.1290, r (train): 0.7865, Test MSE: 0.2214, r (test): -0.1912
Epoch: 54, Training Loss: 0.1216, Train MSE: 0.1216, r (train): 0.8281, Test MSE: 0.2116, r (test): -0.1752
Epoch: 55, Training Loss: 0.0402, Train MSE: 0.0402, r (train): 0.8008, Test MSE: 0.1236, r (test): -0.0510
Epoch: 56, Training Loss: 0.0449, Train MSE: 0.0449, r (train): 0.8031, Test MSE: 0.1147, r (test): -0.0885
Epoch: 57, Training Loss: 0.0177, Train MSE: 0.0177, r (train): 0.8859, Test MSE: 0.0964, r (test): -0.1130
Epoch: 58, Training Loss: 0.0192, Train MSE: 0.0192, r (train): 0.8667, Test MSE: 0.1091, r (test): -0.2563
Epoch: 59, Training Loss: 0.0170, Train MSE: 0.0170, r (train): 0.8834, Test MSE: 0.1039, r (test): -0.2681
Epoch: 60, Training Loss: 0.0174, Train MSE: 0.0174, r (train): 0.9007, Test MSE: 0.1257, r (test): -0.4493
Epoch: 61, Training Loss: 0.0217, Train MSE: 0.0217, r (train): 0.9106, Test MSE: 0.1468, r (test): -0.4590
Epoch: 62, Training Loss: 0.0597, Train MSE: 0.0597, r (train): 0.9189, Test MSE: 0.1741, r (test): -0.4369
Epoch: 63, Training Loss: 0.1156, Train MSE: 0.1156, r (train): 0.9011, Test MSE: 0.2050, r (test): -0.3918
Epoch: 64, Training Loss: 0.1046, Train MSE: 0.1046, r (train): 0.8946, Test MSE: 0.2205, r (test): -0.4400
Epoch: 65, Training Loss: 0.0493, Train MSE: 0.0493, r (train): 0.9029, Test MSE: 0.1704, r (test): -0.2669
Epoch: 66, Training Loss: 0.0209, Train MSE: 0.0209, r (train): 0.8789, Test MSE: 0.1122, r (test): -0.1075
Epoch: 67, Training Loss: 0.0169, Train MSE: 0.0169, r (train): 0.8833, Test MSE: 0.1221, r (test): -0.3289
Epoch: 68, Training Loss: 0.0182, Train MSE: 0.0182, r (train): 0.9048, Test MSE: 0.1379, r (test): -0.4229
Epoch: 69, Training Loss: 0.0321, Train MSE: 0.0321, r (train): 0.9030, Test MSE: 0.1662, r (test): -0.4914
Epoch: 70, Training Loss: 0.0589, Train MSE: 0.0589, r (train): 0.9272, Test MSE: 0.1788, r (test): -0.4228
Epoch: 71, Training Loss: 0.0711, Train MSE: 0.0711, r (train): 0.9132, Test MSE: 0.1709, r (test): -0.3543
Epoch: 72, Training Loss: 0.0618, Train MSE: 0.0618, r (train): 0.9375, Test MSE: 0.1850, r (test): -0.3364
Epoch: 73, Training Loss: 0.0189, Train MSE: 0.0189, r (train): 0.9109, Test MSE: 0.1207, r (test): -0.1779
Epoch: 74, Training Loss: 0.0149, Train MSE: 0.0149, r (train): 0.9065, Test MSE: 0.1251, r (test): -0.3439
Epoch: 75, Training Loss: 0.0197, Train MSE: 0.0197, r (train): 0.9129, Test MSE: 0.1631, r (test): -0.4054
Epoch: 76, Training Loss: 0.0215, Train MSE: 0.0215, r (train): 0.8999, Test MSE: 0.1627, r (test): -0.4673
Epoch: 77, Training Loss: 0.0259, Train MSE: 0.0259, r (train): 0.9233, Test MSE: 0.1618, r (test): -0.3999
Epoch: 78, Training Loss: 0.0292, Train MSE: 0.0292, r (train): 0.9197, Test MSE: 0.1251, r (test): -0.3350
Epoch: 79, Training Loss: 0.0363, Train MSE: 0.0363, r (train): 0.9444, Test MSE: 0.1620, r (test): -0.3855
Epoch: 80, Training Loss: 0.0206, Train MSE: 0.0206, r (train): 0.9308, Test MSE: 0.1359, r (test): -0.4076
Epoch: 81, Training Loss: 0.0134, Train MSE: 0.0134, r (train): 0.9447, Test MSE: 0.1526, r (test): -0.3078
Epoch: 82, Training Loss: 0.0137, Train MSE: 0.0137, r (train): 0.9365, Test MSE: 0.1318, r (test): -0.2135
Epoch: 83, Training Loss: 0.0125, Train MSE: 0.0125, r (train): 0.9342, Test MSE: 0.1332, r (test): -0.2904
Epoch: 84, Training Loss: 0.0185, Train MSE: 0.0185, r (train): 0.9205, Test MSE: 0.1801, r (test): -0.4426
Epoch: 85, Training Loss: 0.0233, Train MSE: 0.0233, r (train): 0.9412, Test MSE: 0.1741, r (test): -0.3795
Epoch: 86, Training Loss: 0.0308, Train MSE: 0.0308, r (train): 0.9374, Test MSE: 0.1930, r (test): -0.3948
Epoch: 87, Training Loss: 0.0215, Train MSE: 0.0215, r (train): 0.9426, Test MSE: 0.1679, r (test): -0.3516
Epoch: 88, Training Loss: 0.0081, Train MSE: 0.0081, r (train): 0.9583, Test MSE: 0.1494, r (test): -0.3262
Epoch: 89, Training Loss: 0.0199, Train MSE: 0.0199, r (train): 0.9453, Test MSE: 0.1608, r (test): -0.3060
Epoch: 90, Training Loss: 0.0248, Train MSE: 0.0248, r (train): 0.9230, Test MSE: 0.1434, r (test): -0.2278
Epoch: 91, Training Loss: 0.0165, Train MSE: 0.0165, r (train): 0.9253, Test MSE: 0.1619, r (test): -0.2763
Epoch: 92, Training Loss: 0.0127, Train MSE: 0.0127, r (train): 0.9267, Test MSE: 0.1676, r (test): -0.4030
Epoch: 93, Training Loss: 0.0137, Train MSE: 0.0137, r (train): 0.9285, Test MSE: 0.1892, r (test): -0.4458
Epoch: 94, Training Loss: 0.0269, Train MSE: 0.0269, r (train): 0.9024, Test MSE: 0.1796, r (test): -0.3438
Epoch: 95, Training Loss: 0.0377, Train MSE: 0.0377, r (train): 0.9189, Test MSE: 0.1370, r (test): -0.3268
Epoch: 96, Training Loss: 0.0216, Train MSE: 0.0216, r (train): 0.9361, Test MSE: 0.1644, r (test): -0.4448
Epoch: 97, Training Loss: 0.0094, Train MSE: 0.0094, r (train): 0.9623, Test MSE: 0.1514, r (test): -0.3093
Epoch: 98, Training Loss: 0.0080, Train MSE: 0.0080, r (train): 0.9532, Test MSE: 0.1333, r (test): -0.1746
Epoch: 99, Training Loss: 0.0104, Train MSE: 0.0104, r (train): 0.9540, Test MSE: 0.1233, r (test): -0.1773
Predicted tensors for training set: 
tensor([ 8.6313e-01,  1.3452e-01,  3.3271e-01,  2.2030e-01,  3.9496e-01,
         4.0623e-01,  3.4103e-01,  6.2472e-02,  6.8646e-01,  5.8690e-01,
         4.1222e-01,  3.7437e-01,  4.7428e-02,  4.4406e-01,  3.0966e-01,
         5.1551e-01, -1.4270e-02,  3.2168e-01,  7.5469e-01,  6.6799e-01,
         7.6315e-02,  6.0287e-01,  2.6874e-01,  6.4501e-01,  2.4481e-01,
         1.9183e-01,  9.3378e-01,  4.9925e-02,  3.0520e-01,  5.9861e-01,
         9.1164e-01,  1.8792e-01,  6.2990e-01,  6.2050e-01,  2.8794e-01,
         9.1708e-01,  3.8007e-01,  5.6607e-01,  7.5789e-01,  4.7223e-01,
         6.4708e-01,  7.6099e-01,  6.3970e-01, -3.7173e-02,  3.7463e-02,
         6.0972e-01,  4.7996e-01,  8.4193e-01,  8.1452e-01,  2.7096e-01,
         4.6572e-01,  3.7205e-01,  3.7590e-01, -8.8655e-04,  6.7258e-01,
         5.9297e-01,  5.3322e-01,  1.0523e+00,  4.6715e-01,  9.4743e-01,
         9.6149e-01,  5.7350e-01,  5.3957e-01,  6.3710e-01,  8.5311e-02,
         7.4201e-01,  7.7251e-01,  9.8130e-01,  9.0402e-01,  1.5296e-01,
         5.5973e-01,  1.3549e-01])
Target tensorsfor training set: 
tensor([0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271])
Correlation for training set: 0.9540197370669424
Predicted tensors for test set: 
tensor([0.1999, 0.5184, 0.1562, 0.4764, 0.2764, 0.5537, 0.6073, 0.9808, 0.5604,
        0.5088, 0.5173, 0.5292, 0.7050, 0.5094, 0.5338, 0.4562, 0.1003, 0.4013])
Target tensors for test set: 
tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411])
Correlation for test set: -0.17730938795179904
Fold 2
Epoch: 00, Training Loss: 0.0946, Train MSE: 0.0946, r (train): 0.2426, Test MSE: 0.0922, r (test): 0.2251
Epoch: 01, Training Loss: 0.0729, Train MSE: 0.0729, r (train): 0.3461, Test MSE: 0.0880, r (test): 0.2175
Epoch: 02, Training Loss: 0.0693, Train MSE: 0.0693, r (train): 0.4182, Test MSE: 0.0935, r (test): 0.1567
Epoch: 03, Training Loss: 0.0709, Train MSE: 0.0709, r (train): 0.4522, Test MSE: 0.1013, r (test): 0.0953
Epoch: 04, Training Loss: 0.0710, Train MSE: 0.0710, r (train): 0.4857, Test MSE: 0.1080, r (test): 0.0580
Epoch: 05, Training Loss: 0.0707, Train MSE: 0.0707, r (train): 0.5152, Test MSE: 0.1153, r (test): 0.0338
Epoch: 06, Training Loss: 0.0692, Train MSE: 0.0692, r (train): 0.5460, Test MSE: 0.1184, r (test): 0.0165
Epoch: 07, Training Loss: 0.0693, Train MSE: 0.0693, r (train): 0.5730, Test MSE: 0.1247, r (test): 0.0007
Epoch: 08, Training Loss: 0.0697, Train MSE: 0.0697, r (train): 0.6061, Test MSE: 0.1345, r (test): -0.0174
Epoch: 09, Training Loss: 0.0716, Train MSE: 0.0716, r (train): 0.6101, Test MSE: 0.1363, r (test): -0.0233
Epoch: 10, Training Loss: 0.0669, Train MSE: 0.0669, r (train): 0.6409, Test MSE: 0.1359, r (test): -0.0365
Epoch: 11, Training Loss: 0.0699, Train MSE: 0.0699, r (train): 0.6559, Test MSE: 0.1461, r (test): -0.0212
Epoch: 12, Training Loss: 0.0522, Train MSE: 0.0522, r (train): 0.7064, Test MSE: 0.1268, r (test): 0.0004
Epoch: 13, Training Loss: 0.0740, Train MSE: 0.0740, r (train): 0.6118, Test MSE: 0.1353, r (test): -0.0316
Epoch: 14, Training Loss: 0.0491, Train MSE: 0.0491, r (train): 0.7426, Test MSE: 0.1065, r (test): -0.0114
Epoch: 15, Training Loss: 0.0658, Train MSE: 0.0658, r (train): 0.6926, Test MSE: 0.1466, r (test): -0.0838
Epoch: 16, Training Loss: 0.0535, Train MSE: 0.0535, r (train): 0.8225, Test MSE: 0.1419, r (test): -0.0398
Epoch: 17, Training Loss: 0.0510, Train MSE: 0.0510, r (train): 0.7788, Test MSE: 0.1283, r (test): 0.0066
Epoch: 18, Training Loss: 0.0394, Train MSE: 0.0394, r (train): 0.7976, Test MSE: 0.1093, r (test): 0.0714
Epoch: 19, Training Loss: 0.0402, Train MSE: 0.0402, r (train): 0.7678, Test MSE: 0.1031, r (test): 0.0716
Epoch: 20, Training Loss: 0.0249, Train MSE: 0.0249, r (train): 0.8858, Test MSE: 0.0968, r (test): 0.0291
Epoch: 21, Training Loss: 0.0296, Train MSE: 0.0296, r (train): 0.8864, Test MSE: 0.1030, r (test): 0.0718
Epoch: 22, Training Loss: 0.0273, Train MSE: 0.0273, r (train): 0.9020, Test MSE: 0.1078, r (test): 0.0176
Epoch: 23, Training Loss: 0.0420, Train MSE: 0.0420, r (train): 0.9158, Test MSE: 0.1308, r (test): 0.0829
Epoch: 24, Training Loss: 0.0550, Train MSE: 0.0550, r (train): 0.8961, Test MSE: 0.1319, r (test): 0.1719
Epoch: 25, Training Loss: 0.0264, Train MSE: 0.0264, r (train): 0.8441, Test MSE: 0.0948, r (test): 0.0980
Epoch: 26, Training Loss: 0.0305, Train MSE: 0.0305, r (train): 0.9008, Test MSE: 0.1134, r (test): 0.0679
Epoch: 27, Training Loss: 0.0286, Train MSE: 0.0286, r (train): 0.8988, Test MSE: 0.1061, r (test): 0.1595
Epoch: 28, Training Loss: 0.0221, Train MSE: 0.0221, r (train): 0.9111, Test MSE: 0.0993, r (test): 0.0232
Epoch: 29, Training Loss: 0.0216, Train MSE: 0.0216, r (train): 0.9311, Test MSE: 0.0971, r (test): 0.1105
Epoch: 30, Training Loss: 0.0073, Train MSE: 0.0073, r (train): 0.9520, Test MSE: 0.0739, r (test): 0.0947
Epoch: 31, Training Loss: 0.0100, Train MSE: 0.0100, r (train): 0.9392, Test MSE: 0.0783, r (test): 0.1371
Epoch: 32, Training Loss: 0.0140, Train MSE: 0.0140, r (train): 0.9026, Test MSE: 0.0681, r (test): 0.1432
Epoch: 33, Training Loss: 0.0145, Train MSE: 0.0145, r (train): 0.8991, Test MSE: 0.0681, r (test): 0.0856
Epoch: 34, Training Loss: 0.0146, Train MSE: 0.0146, r (train): 0.9125, Test MSE: 0.0781, r (test): 0.1279
Epoch: 35, Training Loss: 0.0260, Train MSE: 0.0260, r (train): 0.8958, Test MSE: 0.0957, r (test): 0.1707
Epoch: 36, Training Loss: 0.0880, Train MSE: 0.0880, r (train): 0.8720, Test MSE: 0.1796, r (test): 0.2586
Epoch: 37, Training Loss: 0.0564, Train MSE: 0.0564, r (train): 0.8702, Test MSE: 0.1504, r (test): 0.1709
Epoch: 38, Training Loss: 0.0296, Train MSE: 0.0296, r (train): 0.8702, Test MSE: 0.1054, r (test): 0.1292
Epoch: 39, Training Loss: 0.0425, Train MSE: 0.0425, r (train): 0.7943, Test MSE: 0.1004, r (test): 0.1908
Epoch: 40, Training Loss: 0.0207, Train MSE: 0.0207, r (train): 0.8604, Test MSE: 0.0675, r (test): 0.1862
Epoch: 41, Training Loss: 0.0109, Train MSE: 0.0109, r (train): 0.9340, Test MSE: 0.0592, r (test): 0.3789
Epoch: 42, Training Loss: 0.0299, Train MSE: 0.0299, r (train): 0.9552, Test MSE: 0.1014, r (test): 0.3125
Epoch: 43, Training Loss: 0.0260, Train MSE: 0.0260, r (train): 0.9568, Test MSE: 0.0978, r (test): 0.2619
Epoch: 44, Training Loss: 0.0139, Train MSE: 0.0139, r (train): 0.9223, Test MSE: 0.0801, r (test): 0.0975
Epoch: 45, Training Loss: 0.0143, Train MSE: 0.0143, r (train): 0.9017, Test MSE: 0.0686, r (test): 0.1854
Epoch: 46, Training Loss: 0.0235, Train MSE: 0.0235, r (train): 0.9419, Test MSE: 0.0902, r (test): 0.4227
Epoch: 47, Training Loss: 0.0682, Train MSE: 0.0682, r (train): 0.9369, Test MSE: 0.1558, r (test): 0.2554
Epoch: 48, Training Loss: 0.0254, Train MSE: 0.0254, r (train): 0.9317, Test MSE: 0.1035, r (test): 0.2158
Epoch: 49, Training Loss: 0.0231, Train MSE: 0.0231, r (train): 0.9024, Test MSE: 0.1024, r (test): 0.1185
Epoch: 50, Training Loss: 0.0387, Train MSE: 0.0387, r (train): 0.9307, Test MSE: 0.1204, r (test): 0.3718
Epoch: 51, Training Loss: 0.0728, Train MSE: 0.0728, r (train): 0.9442, Test MSE: 0.1618, r (test): 0.3368
Epoch: 52, Training Loss: 0.0315, Train MSE: 0.0315, r (train): 0.9363, Test MSE: 0.1179, r (test): 0.2097
Epoch: 53, Training Loss: 0.0252, Train MSE: 0.0252, r (train): 0.9032, Test MSE: 0.1044, r (test): 0.1056
Epoch: 54, Training Loss: 0.0602, Train MSE: 0.0602, r (train): 0.9378, Test MSE: 0.1543, r (test): 0.2997
Epoch: 55, Training Loss: 0.0922, Train MSE: 0.0922, r (train): 0.9376, Test MSE: 0.1879, r (test): 0.1602
Epoch: 56, Training Loss: 0.0475, Train MSE: 0.0475, r (train): 0.9280, Test MSE: 0.1178, r (test): 0.1880
Epoch: 57, Training Loss: 0.0132, Train MSE: 0.0132, r (train): 0.9257, Test MSE: 0.0755, r (test): 0.1694
Epoch: 58, Training Loss: 0.0397, Train MSE: 0.0397, r (train): 0.9354, Test MSE: 0.1090, r (test): 0.4734
Epoch: 59, Training Loss: 0.0634, Train MSE: 0.0634, r (train): 0.9427, Test MSE: 0.1392, r (test): 0.1950
Epoch: 60, Training Loss: 0.0189, Train MSE: 0.0189, r (train): 0.9481, Test MSE: 0.0762, r (test): 0.1734
Epoch: 61, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.9172, Test MSE: 0.0748, r (test): -0.0939
Epoch: 62, Training Loss: 0.0310, Train MSE: 0.0310, r (train): 0.9026, Test MSE: 0.0970, r (test): 0.1407
Epoch: 63, Training Loss: 0.0166, Train MSE: 0.0166, r (train): 0.9460, Test MSE: 0.0824, r (test): 0.0885
Epoch: 64, Training Loss: 0.0112, Train MSE: 0.0112, r (train): 0.9621, Test MSE: 0.0686, r (test): -0.0096
Epoch: 65, Training Loss: 0.0074, Train MSE: 0.0074, r (train): 0.9501, Test MSE: 0.0670, r (test): 0.1026
Epoch: 66, Training Loss: 0.0065, Train MSE: 0.0065, r (train): 0.9602, Test MSE: 0.0636, r (test): 0.2462
Epoch: 67, Training Loss: 0.0104, Train MSE: 0.0104, r (train): 0.9665, Test MSE: 0.0617, r (test): 0.1199
Epoch: 68, Training Loss: 0.0055, Train MSE: 0.0055, r (train): 0.9630, Test MSE: 0.0665, r (test): 0.0977
Epoch: 69, Training Loss: 0.0062, Train MSE: 0.0062, r (train): 0.9604, Test MSE: 0.0694, r (test): 0.0733
Epoch: 70, Training Loss: 0.0075, Train MSE: 0.0075, r (train): 0.9521, Test MSE: 0.0704, r (test): 0.0566
Epoch: 71, Training Loss: 0.0205, Train MSE: 0.0205, r (train): 0.9392, Test MSE: 0.0975, r (test): 0.1792
Epoch: 72, Training Loss: 0.0438, Train MSE: 0.0438, r (train): 0.9313, Test MSE: 0.1350, r (test): 0.0073
Epoch: 73, Training Loss: 0.0777, Train MSE: 0.0777, r (train): 0.9195, Test MSE: 0.1901, r (test): -0.0597
Epoch: 74, Training Loss: 0.0688, Train MSE: 0.0688, r (train): 0.9364, Test MSE: 0.1703, r (test): -0.0952
Epoch: 75, Training Loss: 0.0556, Train MSE: 0.0556, r (train): 0.9196, Test MSE: 0.1599, r (test): -0.1731
Epoch: 76, Training Loss: 0.0549, Train MSE: 0.0549, r (train): 0.9189, Test MSE: 0.1526, r (test): -0.0975
Epoch: 77, Training Loss: 0.0603, Train MSE: 0.0603, r (train): 0.9096, Test MSE: 0.1640, r (test): -0.2068
Epoch: 78, Training Loss: 0.0585, Train MSE: 0.0585, r (train): 0.9101, Test MSE: 0.1489, r (test): -0.1462
Epoch: 79, Training Loss: 0.0267, Train MSE: 0.0267, r (train): 0.9277, Test MSE: 0.1009, r (test): 0.0525
Epoch: 80, Training Loss: 0.0117, Train MSE: 0.0117, r (train): 0.9479, Test MSE: 0.0784, r (test): -0.0623
Epoch: 81, Training Loss: 0.0149, Train MSE: 0.0149, r (train): 0.9191, Test MSE: 0.0732, r (test): -0.0682
Epoch: 82, Training Loss: 0.0151, Train MSE: 0.0151, r (train): 0.9110, Test MSE: 0.0799, r (test): -0.1779
Epoch: 83, Training Loss: 0.0164, Train MSE: 0.0164, r (train): 0.9156, Test MSE: 0.0690, r (test): -0.0339
Epoch: 84, Training Loss: 0.0397, Train MSE: 0.0397, r (train): 0.9208, Test MSE: 0.0839, r (test): -0.1087
Epoch: 85, Training Loss: 0.0212, Train MSE: 0.0212, r (train): 0.9525, Test MSE: 0.0761, r (test): -0.1505
Epoch: 86, Training Loss: 0.0094, Train MSE: 0.0094, r (train): 0.9539, Test MSE: 0.0790, r (test): -0.1205
Epoch: 87, Training Loss: 0.0082, Train MSE: 0.0082, r (train): 0.9449, Test MSE: 0.0878, r (test): -0.2131
Epoch: 88, Training Loss: 0.0176, Train MSE: 0.0176, r (train): 0.9394, Test MSE: 0.1226, r (test): -0.1562
Epoch: 89, Training Loss: 0.0523, Train MSE: 0.0523, r (train): 0.9286, Test MSE: 0.1954, r (test): -0.1174
Epoch: 90, Training Loss: 0.0637, Train MSE: 0.0637, r (train): 0.9351, Test MSE: 0.1838, r (test): -0.1819
Epoch: 91, Training Loss: 0.0361, Train MSE: 0.0361, r (train): 0.9410, Test MSE: 0.1483, r (test): -0.2478
Epoch: 92, Training Loss: 0.0216, Train MSE: 0.0216, r (train): 0.9177, Test MSE: 0.1120, r (test): -0.2024
Epoch: 93, Training Loss: 0.0166, Train MSE: 0.0166, r (train): 0.9276, Test MSE: 0.0875, r (test): -0.1475
Epoch: 94, Training Loss: 0.0133, Train MSE: 0.0133, r (train): 0.9356, Test MSE: 0.0698, r (test): -0.0732
Epoch: 95, Training Loss: 0.0280, Train MSE: 0.0280, r (train): 0.9326, Test MSE: 0.0797, r (test): -0.0446
Epoch: 96, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.9516, Test MSE: 0.0775, r (test): -0.1209
Epoch: 97, Training Loss: 0.0134, Train MSE: 0.0134, r (train): 0.9535, Test MSE: 0.0783, r (test): -0.1140
Epoch: 98, Training Loss: 0.0083, Train MSE: 0.0083, r (train): 0.9452, Test MSE: 0.0772, r (test): -0.1950
Epoch: 99, Training Loss: 0.0168, Train MSE: 0.0168, r (train): 0.9404, Test MSE: 0.1004, r (test): -0.0395
Predicted tensors for training set: 
tensor([0.7640, 0.7500, 0.1588, 0.5768, 0.7183, 0.4610, 0.7197, 0.4360, 0.4410,
        0.8597, 1.0111, 0.3415, 0.7103, 0.5186, 0.8461, 0.8000, 0.7851, 0.9196,
        0.8808, 0.8938, 0.2758, 0.6979, 0.3848, 0.7132, 0.3548, 0.1860, 0.8041,
        0.0883, 0.2997, 0.4697, 0.8897, 0.0686, 0.6115, 0.6720, 0.4157, 0.8079,
        0.5121, 0.6496, 0.9164, 0.6392, 0.8645, 1.0218, 0.9547, 0.3926, 0.3947,
        0.9333, 0.9267, 1.1194, 1.0405, 0.6573, 0.7702, 0.7129, 0.7288, 0.3800,
        0.9867, 0.6791, 0.6779, 1.0802, 0.5399, 0.9303, 0.9053, 0.5236, 0.6114,
        0.5958, 0.1213, 0.7507, 0.7959, 0.8580, 0.8830, 0.1477, 0.7571, 0.2615])
Target tensorsfor training set: 
tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271])
Correlation for training set: 0.9404291053935411
Predicted tensors for test set: 
tensor([0.6840, 0.6699, 0.5779, 0.7879, 0.6919, 0.6983, 0.6657, 0.5730, 0.7356,
        0.5556, 0.6723, 0.5747, 0.6539, 0.7138, 0.5543, 0.7363, 0.9021, 0.6979])
Target tensors for test set: 
tensor([0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036])
Correlation for test set: -0.03947703128240606
Fold 3
Epoch: 00, Training Loss: 0.0706, Train MSE: 0.0706, r (train): 0.2871, Test MSE: 0.1580, r (test): 0.0456
Epoch: 01, Training Loss: 0.0544, Train MSE: 0.0544, r (train): 0.4573, Test MSE: 0.1356, r (test): -0.0961
Epoch: 02, Training Loss: 0.0516, Train MSE: 0.0516, r (train): 0.5170, Test MSE: 0.1337, r (test): -0.0026
Epoch: 03, Training Loss: 0.0504, Train MSE: 0.0504, r (train): 0.5650, Test MSE: 0.1375, r (test): -0.0154
Epoch: 04, Training Loss: 0.0488, Train MSE: 0.0488, r (train): 0.5917, Test MSE: 0.1374, r (test): 0.0198
Epoch: 05, Training Loss: 0.0490, Train MSE: 0.0490, r (train): 0.5844, Test MSE: 0.1452, r (test): 0.0229
Epoch: 06, Training Loss: 0.0471, Train MSE: 0.0471, r (train): 0.6304, Test MSE: 0.1448, r (test): 0.0047
Epoch: 07, Training Loss: 0.0451, Train MSE: 0.0451, r (train): 0.6621, Test MSE: 0.1506, r (test): -0.1526
Epoch: 08, Training Loss: 0.0435, Train MSE: 0.0435, r (train): 0.6374, Test MSE: 0.1496, r (test): 0.0250
Epoch: 09, Training Loss: 0.0456, Train MSE: 0.0456, r (train): 0.6660, Test MSE: 0.1608, r (test): -0.3916
Epoch: 10, Training Loss: 0.0377, Train MSE: 0.0377, r (train): 0.6634, Test MSE: 0.1402, r (test): 0.0496
Epoch: 11, Training Loss: 0.0322, Train MSE: 0.0322, r (train): 0.7538, Test MSE: 0.1476, r (test): -0.2637
Epoch: 12, Training Loss: 0.0357, Train MSE: 0.0357, r (train): 0.7445, Test MSE: 0.1525, r (test): -0.0286
Epoch: 13, Training Loss: 0.0296, Train MSE: 0.0296, r (train): 0.7626, Test MSE: 0.1491, r (test): -0.1531
Epoch: 14, Training Loss: 0.0405, Train MSE: 0.0405, r (train): 0.7372, Test MSE: 0.1628, r (test): -0.3017
Epoch: 15, Training Loss: 0.0339, Train MSE: 0.0339, r (train): 0.8118, Test MSE: 0.1590, r (test): -0.1148
Epoch: 16, Training Loss: 0.0268, Train MSE: 0.0268, r (train): 0.7911, Test MSE: 0.1473, r (test): -0.1134
Epoch: 17, Training Loss: 0.0403, Train MSE: 0.0403, r (train): 0.7227, Test MSE: 0.1747, r (test): -0.3354
Epoch: 18, Training Loss: 0.0454, Train MSE: 0.0454, r (train): 0.7637, Test MSE: 0.1786, r (test): 0.0467
Epoch: 19, Training Loss: 0.0233, Train MSE: 0.0233, r (train): 0.8169, Test MSE: 0.1372, r (test): -0.1988
Epoch: 20, Training Loss: 0.0393, Train MSE: 0.0393, r (train): 0.7754, Test MSE: 0.2044, r (test): -0.3791
Epoch: 21, Training Loss: 0.0326, Train MSE: 0.0326, r (train): 0.7734, Test MSE: 0.1395, r (test): 0.0730
Epoch: 22, Training Loss: 0.0192, Train MSE: 0.0192, r (train): 0.8625, Test MSE: 0.1465, r (test): -0.3268
Epoch: 23, Training Loss: 0.0151, Train MSE: 0.0151, r (train): 0.8890, Test MSE: 0.1444, r (test): -0.1856
Epoch: 24, Training Loss: 0.0207, Train MSE: 0.0207, r (train): 0.8762, Test MSE: 0.1518, r (test): -0.3204
Epoch: 25, Training Loss: 0.0210, Train MSE: 0.0210, r (train): 0.9245, Test MSE: 0.1729, r (test): -0.2788
Epoch: 26, Training Loss: 0.0297, Train MSE: 0.0297, r (train): 0.7994, Test MSE: 0.1441, r (test): 0.0335
Epoch: 27, Training Loss: 0.0175, Train MSE: 0.0175, r (train): 0.8695, Test MSE: 0.1499, r (test): -0.3671
Epoch: 28, Training Loss: 0.0281, Train MSE: 0.0281, r (train): 0.9080, Test MSE: 0.1867, r (test): -0.2581
Epoch: 29, Training Loss: 0.0337, Train MSE: 0.0337, r (train): 0.7798, Test MSE: 0.1397, r (test): 0.0739
Epoch: 30, Training Loss: 0.0403, Train MSE: 0.0403, r (train): 0.8190, Test MSE: 0.2015, r (test): -0.4590
Epoch: 31, Training Loss: 0.0412, Train MSE: 0.0412, r (train): 0.8019, Test MSE: 0.1697, r (test): -0.0298
Epoch: 32, Training Loss: 0.0173, Train MSE: 0.0173, r (train): 0.9026, Test MSE: 0.1609, r (test): -0.2964
Epoch: 33, Training Loss: 0.0466, Train MSE: 0.0466, r (train): 0.8483, Test MSE: 0.2077, r (test): -0.3576
Epoch: 34, Training Loss: 0.0329, Train MSE: 0.0329, r (train): 0.8554, Test MSE: 0.1625, r (test): -0.1436
Epoch: 35, Training Loss: 0.0360, Train MSE: 0.0360, r (train): 0.8896, Test MSE: 0.1731, r (test): -0.3229
Epoch: 36, Training Loss: 0.0186, Train MSE: 0.0186, r (train): 0.8977, Test MSE: 0.1492, r (test): -0.2533
Epoch: 37, Training Loss: 0.0224, Train MSE: 0.0224, r (train): 0.8359, Test MSE: 0.1329, r (test): -0.2488
Epoch: 38, Training Loss: 0.0158, Train MSE: 0.0158, r (train): 0.8879, Test MSE: 0.1574, r (test): -0.3712
Epoch: 39, Training Loss: 0.0348, Train MSE: 0.0348, r (train): 0.8204, Test MSE: 0.1482, r (test): -0.1811
Epoch: 40, Training Loss: 0.0677, Train MSE: 0.0677, r (train): 0.8436, Test MSE: 0.1908, r (test): -0.1553
Epoch: 41, Training Loss: 0.0588, Train MSE: 0.0588, r (train): 0.8454, Test MSE: 0.1957, r (test): -0.1266
Epoch: 42, Training Loss: 0.0224, Train MSE: 0.0224, r (train): 0.8562, Test MSE: 0.1551, r (test): -0.3098
Epoch: 43, Training Loss: 0.0247, Train MSE: 0.0247, r (train): 0.8418, Test MSE: 0.1349, r (test): -0.2132
Epoch: 44, Training Loss: 0.0356, Train MSE: 0.0356, r (train): 0.8863, Test MSE: 0.1637, r (test): -0.2930
Epoch: 45, Training Loss: 0.0369, Train MSE: 0.0369, r (train): 0.8927, Test MSE: 0.1737, r (test): -0.2356
Epoch: 46, Training Loss: 0.0293, Train MSE: 0.0293, r (train): 0.9081, Test MSE: 0.1714, r (test): -0.3259
Epoch: 47, Training Loss: 0.0216, Train MSE: 0.0216, r (train): 0.8685, Test MSE: 0.1415, r (test): -0.3267
Epoch: 48, Training Loss: 0.0307, Train MSE: 0.0307, r (train): 0.8704, Test MSE: 0.1622, r (test): -0.3919
Epoch: 49, Training Loss: 0.0473, Train MSE: 0.0473, r (train): 0.8628, Test MSE: 0.1814, r (test): -0.3652
Epoch: 50, Training Loss: 0.0603, Train MSE: 0.0603, r (train): 0.8891, Test MSE: 0.2124, r (test): -0.2542
Epoch: 51, Training Loss: 0.0181, Train MSE: 0.0181, r (train): 0.8883, Test MSE: 0.1636, r (test): -0.3784
Epoch: 52, Training Loss: 0.0206, Train MSE: 0.0206, r (train): 0.8721, Test MSE: 0.1473, r (test): -0.4290
Epoch: 53, Training Loss: 0.0450, Train MSE: 0.0450, r (train): 0.8911, Test MSE: 0.1937, r (test): -0.4740
Epoch: 54, Training Loss: 0.0392, Train MSE: 0.0392, r (train): 0.8991, Test MSE: 0.1921, r (test): -0.3659
Epoch: 55, Training Loss: 0.0211, Train MSE: 0.0211, r (train): 0.8771, Test MSE: 0.1484, r (test): -0.3632
Epoch: 56, Training Loss: 0.0252, Train MSE: 0.0252, r (train): 0.8339, Test MSE: 0.1482, r (test): -0.4643
Epoch: 57, Training Loss: 0.0527, Train MSE: 0.0527, r (train): 0.8508, Test MSE: 0.1865, r (test): -0.4007
Epoch: 58, Training Loss: 0.0370, Train MSE: 0.0370, r (train): 0.8574, Test MSE: 0.1877, r (test): -0.3034
Epoch: 59, Training Loss: 0.0314, Train MSE: 0.0314, r (train): 0.9045, Test MSE: 0.1847, r (test): -0.3644
Epoch: 60, Training Loss: 0.0447, Train MSE: 0.0447, r (train): 0.8623, Test MSE: 0.1635, r (test): -0.3106
Epoch: 61, Training Loss: 0.0642, Train MSE: 0.0642, r (train): 0.8921, Test MSE: 0.2010, r (test): -0.3006
Epoch: 62, Training Loss: 0.0460, Train MSE: 0.0460, r (train): 0.9024, Test MSE: 0.1946, r (test): -0.2985
Epoch: 63, Training Loss: 0.0340, Train MSE: 0.0340, r (train): 0.8727, Test MSE: 0.1687, r (test): -0.4216
Epoch: 64, Training Loss: 0.0511, Train MSE: 0.0511, r (train): 0.8677, Test MSE: 0.1797, r (test): -0.3304
Epoch: 65, Training Loss: 0.0775, Train MSE: 0.0775, r (train): 0.8731, Test MSE: 0.2170, r (test): -0.3112
Epoch: 66, Training Loss: 0.0540, Train MSE: 0.0540, r (train): 0.8919, Test MSE: 0.2045, r (test): -0.2567
Epoch: 67, Training Loss: 0.0209, Train MSE: 0.0209, r (train): 0.8887, Test MSE: 0.1517, r (test): -0.3819
Epoch: 68, Training Loss: 0.0411, Train MSE: 0.0411, r (train): 0.8845, Test MSE: 0.1756, r (test): -0.3298
Epoch: 69, Training Loss: 0.0741, Train MSE: 0.0741, r (train): 0.8218, Test MSE: 0.1940, r (test): -0.1273
Epoch: 70, Training Loss: 0.0696, Train MSE: 0.0696, r (train): 0.8357, Test MSE: 0.2251, r (test): -0.3921
Epoch: 71, Training Loss: 0.0399, Train MSE: 0.0399, r (train): 0.8948, Test MSE: 0.1761, r (test): -0.2878
Epoch: 72, Training Loss: 0.0379, Train MSE: 0.0379, r (train): 0.8954, Test MSE: 0.1792, r (test): -0.3816
Epoch: 73, Training Loss: 0.0473, Train MSE: 0.0473, r (train): 0.8903, Test MSE: 0.1848, r (test): -0.3440
Epoch: 74, Training Loss: 0.0506, Train MSE: 0.0506, r (train): 0.8474, Test MSE: 0.1753, r (test): -0.4395
Epoch: 75, Training Loss: 0.0848, Train MSE: 0.0848, r (train): 0.8777, Test MSE: 0.2145, r (test): -0.3636
Epoch: 76, Training Loss: 0.0975, Train MSE: 0.0975, r (train): 0.8752, Test MSE: 0.2483, r (test): -0.3549
Epoch: 77, Training Loss: 0.0545, Train MSE: 0.0545, r (train): 0.8870, Test MSE: 0.1958, r (test): -0.3914
Epoch: 78, Training Loss: 0.0450, Train MSE: 0.0450, r (train): 0.8494, Test MSE: 0.1791, r (test): -0.4835
Epoch: 79, Training Loss: 0.0792, Train MSE: 0.0792, r (train): 0.8417, Test MSE: 0.1904, r (test): -0.3487
Epoch: 80, Training Loss: 0.0958, Train MSE: 0.0958, r (train): 0.8511, Test MSE: 0.2251, r (test): -0.3194
Epoch: 81, Training Loss: 0.0505, Train MSE: 0.0505, r (train): 0.8644, Test MSE: 0.1836, r (test): -0.3027
Epoch: 82, Training Loss: 0.0413, Train MSE: 0.0413, r (train): 0.8789, Test MSE: 0.1700, r (test): -0.3295
Epoch: 83, Training Loss: 0.0710, Train MSE: 0.0710, r (train): 0.8365, Test MSE: 0.1854, r (test): -0.4039
Epoch: 84, Training Loss: 0.0595, Train MSE: 0.0595, r (train): 0.8589, Test MSE: 0.1805, r (test): -0.3789
Epoch: 85, Training Loss: 0.0207, Train MSE: 0.0207, r (train): 0.8704, Test MSE: 0.1489, r (test): -0.3928
Epoch: 86, Training Loss: 0.0415, Train MSE: 0.0415, r (train): 0.8746, Test MSE: 0.1705, r (test): -0.4005
Epoch: 87, Training Loss: 0.0579, Train MSE: 0.0579, r (train): 0.8740, Test MSE: 0.1776, r (test): -0.3063
Epoch: 88, Training Loss: 0.0588, Train MSE: 0.0588, r (train): 0.8752, Test MSE: 0.1854, r (test): -0.3672
Epoch: 89, Training Loss: 0.0301, Train MSE: 0.0301, r (train): 0.8759, Test MSE: 0.1728, r (test): -0.4276
Epoch: 90, Training Loss: 0.0436, Train MSE: 0.0436, r (train): 0.8686, Test MSE: 0.1656, r (test): -0.3883
Epoch: 91, Training Loss: 0.0873, Train MSE: 0.0873, r (train): 0.8418, Test MSE: 0.2034, r (test): -0.3898
Epoch: 92, Training Loss: 0.0553, Train MSE: 0.0553, r (train): 0.8865, Test MSE: 0.1893, r (test): -0.4297
Epoch: 93, Training Loss: 0.0267, Train MSE: 0.0267, r (train): 0.8870, Test MSE: 0.1603, r (test): -0.4120
Epoch: 94, Training Loss: 0.0367, Train MSE: 0.0367, r (train): 0.8932, Test MSE: 0.1689, r (test): -0.3929
Epoch: 95, Training Loss: 0.0326, Train MSE: 0.0326, r (train): 0.8848, Test MSE: 0.1593, r (test): -0.4402
Epoch: 96, Training Loss: 0.0277, Train MSE: 0.0277, r (train): 0.8661, Test MSE: 0.1586, r (test): -0.4625
Epoch: 97, Training Loss: 0.0274, Train MSE: 0.0274, r (train): 0.8951, Test MSE: 0.1692, r (test): -0.4477
Epoch: 98, Training Loss: 0.0321, Train MSE: 0.0321, r (train): 0.8819, Test MSE: 0.1773, r (test): -0.5057
Epoch: 99, Training Loss: 0.0278, Train MSE: 0.0278, r (train): 0.8958, Test MSE: 0.1725, r (test): -0.5061
Predicted tensors for training set: 
tensor([0.8828, 0.6687, 0.0929, 0.4220, 0.6130, 0.2335, 0.5514, 0.2093, 0.2082,
        0.7505, 0.8836, 0.0829, 0.4983, 0.3606, 0.6618, 0.6317, 0.5741, 0.8251,
        0.9110, 0.2179, 0.3727, 0.2737, 0.5471, 0.5306, 0.4911, 0.0610, 0.9653,
        0.8896, 0.5868, 0.6629, 0.1353, 0.7811, 0.5690, 0.7776, 0.3226, 0.5625,
        0.5560, 0.8510, 1.1322, 0.7546, 1.0402, 1.2550, 1.0876, 0.3484, 0.4080,
        1.0431, 0.8939, 1.2200, 1.2369, 0.7387, 0.8142, 0.7203, 0.6727, 0.2966,
        1.0229, 0.7332, 0.7413, 1.1705, 0.5882, 1.0468, 1.0441, 0.5338, 0.7022,
        0.6774, 0.1671, 0.8300, 0.8860, 0.9595, 0.9076, 0.1845, 0.6335, 0.2629])
Target tensorsfor training set: 
tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271])
Correlation for training set: 0.8957574644499405
Predicted tensors for test set: 
tensor([0.5676, 0.5296, 0.6170, 0.6140, 0.7887, 0.4885, 0.7245, 0.7161, 0.7115,
        0.6525, 0.5492, 0.5564, 0.3563, 0.7798, 0.7858, 0.7714, 0.7342, 0.3052])
Target tensors for test set: 
tensor([0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391])
Correlation for test set: -0.5060968429947621
Fold 4
Epoch: 00, Training Loss: 0.0865, Train MSE: 0.0865, r (train): 0.1891, Test MSE: 0.0820, r (test): -0.3340
Epoch: 01, Training Loss: 0.0874, Train MSE: 0.0874, r (train): 0.2352, Test MSE: 0.0905, r (test): -0.3475
Epoch: 02, Training Loss: 0.0911, Train MSE: 0.0911, r (train): 0.2653, Test MSE: 0.0977, r (test): -0.3707
Epoch: 03, Training Loss: 0.0902, Train MSE: 0.0902, r (train): 0.3115, Test MSE: 0.0980, r (test): -0.3727
Epoch: 04, Training Loss: 0.0827, Train MSE: 0.0827, r (train): 0.3697, Test MSE: 0.0933, r (test): -0.3786
Epoch: 05, Training Loss: 0.0818, Train MSE: 0.0818, r (train): 0.4281, Test MSE: 0.0930, r (test): -0.3447
Epoch: 06, Training Loss: 0.0728, Train MSE: 0.0728, r (train): 0.4955, Test MSE: 0.0895, r (test): -0.2918
Epoch: 07, Training Loss: 0.0739, Train MSE: 0.0739, r (train): 0.5030, Test MSE: 0.0898, r (test): -0.3022
Epoch: 08, Training Loss: 0.0617, Train MSE: 0.0617, r (train): 0.5906, Test MSE: 0.0850, r (test): -0.2585
Epoch: 09, Training Loss: 0.0644, Train MSE: 0.0644, r (train): 0.5704, Test MSE: 0.0836, r (test): -0.2177
Epoch: 10, Training Loss: 0.0578, Train MSE: 0.0578, r (train): 0.6400, Test MSE: 0.0851, r (test): -0.1803
Epoch: 11, Training Loss: 0.0644, Train MSE: 0.0644, r (train): 0.5963, Test MSE: 0.0828, r (test): -0.1762
Epoch: 12, Training Loss: 0.0587, Train MSE: 0.0587, r (train): 0.6518, Test MSE: 0.0848, r (test): -0.1715
Epoch: 13, Training Loss: 0.0543, Train MSE: 0.0543, r (train): 0.6998, Test MSE: 0.0807, r (test): -0.0171
Epoch: 14, Training Loss: 0.0514, Train MSE: 0.0514, r (train): 0.7644, Test MSE: 0.0856, r (test): -0.0499
Epoch: 15, Training Loss: 0.0448, Train MSE: 0.0448, r (train): 0.6410, Test MSE: 0.0783, r (test): -0.2000
Epoch: 16, Training Loss: 0.0618, Train MSE: 0.0618, r (train): 0.6953, Test MSE: 0.0816, r (test): 0.0350
Epoch: 17, Training Loss: 0.0826, Train MSE: 0.0826, r (train): 0.6961, Test MSE: 0.0979, r (test): -0.0927
Epoch: 18, Training Loss: 0.0599, Train MSE: 0.0599, r (train): 0.7645, Test MSE: 0.1010, r (test): -0.2179
Epoch: 19, Training Loss: 0.0342, Train MSE: 0.0342, r (train): 0.8276, Test MSE: 0.0887, r (test): -0.2936
Epoch: 20, Training Loss: 0.0439, Train MSE: 0.0439, r (train): 0.8275, Test MSE: 0.0840, r (test): -0.0244
Epoch: 21, Training Loss: 0.0668, Train MSE: 0.0668, r (train): 0.8161, Test MSE: 0.0926, r (test): 0.0346
Epoch: 22, Training Loss: 0.0571, Train MSE: 0.0571, r (train): 0.8639, Test MSE: 0.0966, r (test): -0.0188
Epoch: 23, Training Loss: 0.0654, Train MSE: 0.0654, r (train): 0.8369, Test MSE: 0.1055, r (test): -0.1107
Epoch: 24, Training Loss: 0.0253, Train MSE: 0.0253, r (train): 0.8882, Test MSE: 0.0761, r (test): 0.0743
Epoch: 25, Training Loss: 0.0338, Train MSE: 0.0338, r (train): 0.8696, Test MSE: 0.0730, r (test): 0.1652
Epoch: 26, Training Loss: 0.0331, Train MSE: 0.0331, r (train): 0.8830, Test MSE: 0.0712, r (test): 0.2323
Epoch: 27, Training Loss: 0.0639, Train MSE: 0.0639, r (train): 0.9078, Test MSE: 0.0986, r (test): 0.1818
Epoch: 28, Training Loss: 0.0691, Train MSE: 0.0691, r (train): 0.8901, Test MSE: 0.1059, r (test): 0.0312
Epoch: 29, Training Loss: 0.0409, Train MSE: 0.0409, r (train): 0.8874, Test MSE: 0.0953, r (test): -0.0747
Epoch: 30, Training Loss: 0.0177, Train MSE: 0.0177, r (train): 0.8827, Test MSE: 0.0740, r (test): 0.0763
Epoch: 31, Training Loss: 0.0334, Train MSE: 0.0334, r (train): 0.8123, Test MSE: 0.0979, r (test): 0.1738
Epoch: 32, Training Loss: 0.0391, Train MSE: 0.0391, r (train): 0.7609, Test MSE: 0.0712, r (test): 0.1971
Epoch: 33, Training Loss: 0.0543, Train MSE: 0.0543, r (train): 0.8588, Test MSE: 0.1010, r (test): -0.0062
Epoch: 34, Training Loss: 0.0203, Train MSE: 0.0203, r (train): 0.8829, Test MSE: 0.0909, r (test): -0.1895
Epoch: 35, Training Loss: 0.0277, Train MSE: 0.0277, r (train): 0.9045, Test MSE: 0.1060, r (test): 0.0584
Epoch: 36, Training Loss: 0.0294, Train MSE: 0.0294, r (train): 0.8014, Test MSE: 0.0798, r (test): 0.0134
Epoch: 37, Training Loss: 0.0270, Train MSE: 0.0270, r (train): 0.8568, Test MSE: 0.0889, r (test): -0.0970
Epoch: 38, Training Loss: 0.0132, Train MSE: 0.0132, r (train): 0.9114, Test MSE: 0.0837, r (test): -0.0702
Epoch: 39, Training Loss: 0.0124, Train MSE: 0.0124, r (train): 0.9240, Test MSE: 0.0787, r (test): -0.0126
Epoch: 40, Training Loss: 0.0103, Train MSE: 0.0103, r (train): 0.9355, Test MSE: 0.0792, r (test): -0.0445
Epoch: 41, Training Loss: 0.0377, Train MSE: 0.0377, r (train): 0.9394, Test MSE: 0.0940, r (test): -0.0570
Epoch: 42, Training Loss: 0.0424, Train MSE: 0.0424, r (train): 0.9444, Test MSE: 0.1108, r (test): -0.1869
Epoch: 43, Training Loss: 0.0248, Train MSE: 0.0248, r (train): 0.9426, Test MSE: 0.0912, r (test): -0.0851
Epoch: 44, Training Loss: 0.0194, Train MSE: 0.0194, r (train): 0.9200, Test MSE: 0.0762, r (test): 0.1052
Epoch: 45, Training Loss: 0.0590, Train MSE: 0.0590, r (train): 0.9118, Test MSE: 0.0981, r (test): 0.1154
Epoch: 46, Training Loss: 0.0612, Train MSE: 0.0612, r (train): 0.9123, Test MSE: 0.1150, r (test): -0.1955
Epoch: 47, Training Loss: 0.0242, Train MSE: 0.0242, r (train): 0.9089, Test MSE: 0.0915, r (test): -0.0595
Epoch: 48, Training Loss: 0.0190, Train MSE: 0.0190, r (train): 0.9372, Test MSE: 0.0976, r (test): 0.0318
Epoch: 49, Training Loss: 0.0182, Train MSE: 0.0182, r (train): 0.8806, Test MSE: 0.0795, r (test): 0.0069
Epoch: 50, Training Loss: 0.0191, Train MSE: 0.0191, r (train): 0.8868, Test MSE: 0.0900, r (test): -0.1608
Epoch: 51, Training Loss: 0.0169, Train MSE: 0.0169, r (train): 0.9013, Test MSE: 0.0993, r (test): -0.2627
Epoch: 52, Training Loss: 0.0184, Train MSE: 0.0184, r (train): 0.9216, Test MSE: 0.1070, r (test): -0.2644
Epoch: 53, Training Loss: 0.0109, Train MSE: 0.0109, r (train): 0.9287, Test MSE: 0.0943, r (test): -0.2252
Epoch: 54, Training Loss: 0.0151, Train MSE: 0.0151, r (train): 0.9361, Test MSE: 0.0987, r (test): -0.3083
Epoch: 55, Training Loss: 0.0346, Train MSE: 0.0346, r (train): 0.9364, Test MSE: 0.1028, r (test): -0.2131
Epoch: 56, Training Loss: 0.0409, Train MSE: 0.0409, r (train): 0.9155, Test MSE: 0.0904, r (test): -0.0383
Epoch: 57, Training Loss: 0.0497, Train MSE: 0.0497, r (train): 0.9180, Test MSE: 0.0984, r (test): 0.0015
Epoch: 58, Training Loss: 0.0236, Train MSE: 0.0236, r (train): 0.9231, Test MSE: 0.0795, r (test): 0.0772
Epoch: 59, Training Loss: 0.0269, Train MSE: 0.0269, r (train): 0.9008, Test MSE: 0.0945, r (test): -0.1444
Epoch: 60, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.8802, Test MSE: 0.0811, r (test): -0.0331
Epoch: 61, Training Loss: 0.0285, Train MSE: 0.0285, r (train): 0.8253, Test MSE: 0.1072, r (test): -0.1824
Epoch: 62, Training Loss: 0.0136, Train MSE: 0.0136, r (train): 0.9429, Test MSE: 0.1008, r (test): -0.2510
Epoch: 63, Training Loss: 0.0104, Train MSE: 0.0104, r (train): 0.9498, Test MSE: 0.0977, r (test): -0.3177
Epoch: 64, Training Loss: 0.0247, Train MSE: 0.0247, r (train): 0.9459, Test MSE: 0.0971, r (test): -0.1748
Epoch: 65, Training Loss: 0.0317, Train MSE: 0.0317, r (train): 0.9420, Test MSE: 0.0961, r (test): -0.1375
Epoch: 66, Training Loss: 0.0107, Train MSE: 0.0107, r (train): 0.9460, Test MSE: 0.0894, r (test): -0.1252
Epoch: 67, Training Loss: 0.0233, Train MSE: 0.0233, r (train): 0.8973, Test MSE: 0.1037, r (test): -0.1015
Epoch: 68, Training Loss: 0.0176, Train MSE: 0.0176, r (train): 0.9089, Test MSE: 0.1045, r (test): -0.1670
Epoch: 69, Training Loss: 0.0112, Train MSE: 0.0112, r (train): 0.9267, Test MSE: 0.0941, r (test): -0.2048
Epoch: 70, Training Loss: 0.0101, Train MSE: 0.0101, r (train): 0.9289, Test MSE: 0.1005, r (test): -0.3270
Epoch: 71, Training Loss: 0.0224, Train MSE: 0.0224, r (train): 0.9490, Test MSE: 0.0905, r (test): -0.0930
Epoch: 72, Training Loss: 0.0121, Train MSE: 0.0121, r (train): 0.9440, Test MSE: 0.0858, r (test): -0.0303
Epoch: 73, Training Loss: 0.0141, Train MSE: 0.0141, r (train): 0.9206, Test MSE: 0.0832, r (test): 0.0456
Epoch: 74, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.8900, Test MSE: 0.0955, r (test): -0.0582
Epoch: 75, Training Loss: 0.0071, Train MSE: 0.0071, r (train): 0.9506, Test MSE: 0.0915, r (test): -0.1567
Epoch: 76, Training Loss: 0.0093, Train MSE: 0.0093, r (train): 0.9406, Test MSE: 0.0908, r (test): -0.0646
Epoch: 77, Training Loss: 0.0184, Train MSE: 0.0184, r (train): 0.9457, Test MSE: 0.0859, r (test): -0.0241
Epoch: 78, Training Loss: 0.0126, Train MSE: 0.0126, r (train): 0.9492, Test MSE: 0.0846, r (test): -0.0399
Epoch: 79, Training Loss: 0.0111, Train MSE: 0.0111, r (train): 0.9430, Test MSE: 0.0846, r (test): 0.0639
Epoch: 80, Training Loss: 0.0293, Train MSE: 0.0293, r (train): 0.9190, Test MSE: 0.1052, r (test): 0.0494
Epoch: 81, Training Loss: 0.0206, Train MSE: 0.0206, r (train): 0.9196, Test MSE: 0.1140, r (test): -0.2370
Epoch: 82, Training Loss: 0.0092, Train MSE: 0.0092, r (train): 0.9537, Test MSE: 0.0981, r (test): -0.1164
Epoch: 83, Training Loss: 0.0080, Train MSE: 0.0080, r (train): 0.9555, Test MSE: 0.0978, r (test): -0.3261
Epoch: 84, Training Loss: 0.0099, Train MSE: 0.0099, r (train): 0.9538, Test MSE: 0.0814, r (test): -0.0651
Epoch: 85, Training Loss: 0.0166, Train MSE: 0.0166, r (train): 0.9617, Test MSE: 0.1109, r (test): -0.1763
Epoch: 86, Training Loss: 0.0323, Train MSE: 0.0323, r (train): 0.9580, Test MSE: 0.1351, r (test): -0.1136
Epoch: 87, Training Loss: 0.0083, Train MSE: 0.0083, r (train): 0.9673, Test MSE: 0.1076, r (test): -0.2726
Epoch: 88, Training Loss: 0.0124, Train MSE: 0.0124, r (train): 0.9537, Test MSE: 0.0836, r (test): -0.0941
Epoch: 89, Training Loss: 0.0175, Train MSE: 0.0175, r (train): 0.9162, Test MSE: 0.0921, r (test): -0.1946
Epoch: 90, Training Loss: 0.0143, Train MSE: 0.0143, r (train): 0.9462, Test MSE: 0.0845, r (test): -0.0672
Epoch: 91, Training Loss: 0.0106, Train MSE: 0.0106, r (train): 0.9626, Test MSE: 0.0881, r (test): 0.0651
Epoch: 92, Training Loss: 0.0175, Train MSE: 0.0175, r (train): 0.9277, Test MSE: 0.0927, r (test): 0.0422
Epoch: 93, Training Loss: 0.0150, Train MSE: 0.0150, r (train): 0.9369, Test MSE: 0.0969, r (test): -0.0857
Epoch: 94, Training Loss: 0.0114, Train MSE: 0.0114, r (train): 0.9478, Test MSE: 0.1114, r (test): -0.2851
Epoch: 95, Training Loss: 0.0092, Train MSE: 0.0092, r (train): 0.9442, Test MSE: 0.0992, r (test): -0.2124
Epoch: 96, Training Loss: 0.0223, Train MSE: 0.0223, r (train): 0.9513, Test MSE: 0.0797, r (test): 0.0504
Epoch: 97, Training Loss: 0.0075, Train MSE: 0.0075, r (train): 0.9590, Test MSE: 0.0854, r (test): -0.0707
Epoch: 98, Training Loss: 0.0104, Train MSE: 0.0104, r (train): 0.9623, Test MSE: 0.0887, r (test): 0.0632
Epoch: 99, Training Loss: 0.0190, Train MSE: 0.0190, r (train): 0.9330, Test MSE: 0.0923, r (test): 0.0734
Predicted tensors for training set: 
tensor([ 0.6798,  0.6295,  0.0967,  0.4057,  0.5342,  0.3277,  0.5244,  0.1768,
         0.2467,  0.5939,  0.8052,  0.1964,  0.4438,  0.3417,  0.4463,  0.5255,
         0.4781,  0.3351,  0.5553,  0.2261,  0.3512,  0.2202,  0.4644,  0.4467,
         0.4667,  0.0695,  0.7644,  0.8170,  0.4658,  0.4670,  0.0937,  0.7333,
         0.5709,  0.6340,  0.1430,  0.4114,  0.8586,  0.7174,  0.1036,  0.6082,
         0.2972,  0.5969,  0.2091,  0.0858,  0.7534, -0.0845,  0.1138,  0.3535,
         0.7712, -0.1162,  0.4779,  0.4684,  0.1906,  0.6329,  0.5805,  0.4080,
         0.2945,  0.8394,  0.4240,  0.7784,  0.7370,  0.3806,  0.4453,  0.5180,
         0.0682,  0.6876,  0.8084,  0.9534,  0.8559,  0.0595,  0.6486,  0.0986])
Target tensorsfor training set: 
tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271])
Correlation for training set: 0.9329824645833208
Predicted tensors for test set: 
tensor([0.2819, 0.4631, 0.3704, 0.5499, 0.4412, 0.2974, 0.5466, 0.3389, 0.5106,
        0.3701, 0.3915, 0.4828, 0.5400, 0.5483, 0.2990, 0.2774, 0.4589, 0.4349])
Target tensors for test set: 
tensor([0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478])
Correlation for test set: 0.07339444917780703
Fold 5
Epoch: 00, Training Loss: 0.0732, Train MSE: 0.0732, r (train): 0.3864, Test MSE: 0.1585, r (test): -0.5073
Epoch: 01, Training Loss: 0.0661, Train MSE: 0.0661, r (train): 0.3873, Test MSE: 0.1537, r (test): -0.5455
Epoch: 02, Training Loss: 0.0563, Train MSE: 0.0563, r (train): 0.4717, Test MSE: 0.1370, r (test): -0.5079
Epoch: 03, Training Loss: 0.0527, Train MSE: 0.0527, r (train): 0.5208, Test MSE: 0.1314, r (test): -0.4795
Epoch: 04, Training Loss: 0.0517, Train MSE: 0.0517, r (train): 0.5440, Test MSE: 0.1380, r (test): -0.4805
Epoch: 05, Training Loss: 0.0538, Train MSE: 0.0538, r (train): 0.5510, Test MSE: 0.1395, r (test): -0.4683
Epoch: 06, Training Loss: 0.0570, Train MSE: 0.0570, r (train): 0.5583, Test MSE: 0.1451, r (test): -0.4679
Epoch: 07, Training Loss: 0.0515, Train MSE: 0.0515, r (train): 0.5950, Test MSE: 0.1358, r (test): -0.4365
Epoch: 08, Training Loss: 0.0591, Train MSE: 0.0591, r (train): 0.5932, Test MSE: 0.1315, r (test): -0.4211
Epoch: 09, Training Loss: 0.0506, Train MSE: 0.0506, r (train): 0.6174, Test MSE: 0.1346, r (test): -0.4068
Epoch: 10, Training Loss: 0.0466, Train MSE: 0.0466, r (train): 0.6384, Test MSE: 0.1218, r (test): -0.3824
Epoch: 11, Training Loss: 0.0918, Train MSE: 0.0918, r (train): 0.4903, Test MSE: 0.1845, r (test): -0.4585
Epoch: 12, Training Loss: 0.0550, Train MSE: 0.0550, r (train): 0.5877, Test MSE: 0.1553, r (test): -0.4188
Epoch: 13, Training Loss: 0.0773, Train MSE: 0.0773, r (train): 0.6305, Test MSE: 0.1369, r (test): -0.3391
Epoch: 14, Training Loss: 0.0519, Train MSE: 0.0519, r (train): 0.6311, Test MSE: 0.1189, r (test): -0.2783
Epoch: 15, Training Loss: 0.0573, Train MSE: 0.0573, r (train): 0.6705, Test MSE: 0.1226, r (test): -0.3061
Epoch: 16, Training Loss: 0.0754, Train MSE: 0.0754, r (train): 0.6958, Test MSE: 0.1496, r (test): -0.3255
Epoch: 17, Training Loss: 0.0754, Train MSE: 0.0754, r (train): 0.7121, Test MSE: 0.1551, r (test): -0.2972
Epoch: 18, Training Loss: 0.0706, Train MSE: 0.0706, r (train): 0.7165, Test MSE: 0.1272, r (test): -0.1454
Epoch: 19, Training Loss: 0.0398, Train MSE: 0.0398, r (train): 0.7452, Test MSE: 0.1216, r (test): -0.2401
Epoch: 20, Training Loss: 0.0730, Train MSE: 0.0730, r (train): 0.7282, Test MSE: 0.1318, r (test): -0.1525
Epoch: 21, Training Loss: 0.0714, Train MSE: 0.0714, r (train): 0.7918, Test MSE: 0.1505, r (test): -0.1992
Epoch: 22, Training Loss: 0.0905, Train MSE: 0.0905, r (train): 0.7816, Test MSE: 0.1587, r (test): -0.1334
Epoch: 23, Training Loss: 0.0627, Train MSE: 0.0627, r (train): 0.7183, Test MSE: 0.1247, r (test): -0.0836
Epoch: 24, Training Loss: 0.0350, Train MSE: 0.0350, r (train): 0.7543, Test MSE: 0.1011, r (test): -0.2089
Epoch: 25, Training Loss: 0.0739, Train MSE: 0.0739, r (train): 0.7393, Test MSE: 0.1520, r (test): -0.3026
Epoch: 26, Training Loss: 0.0885, Train MSE: 0.0885, r (train): 0.8191, Test MSE: 0.1486, r (test): -0.1415
Epoch: 27, Training Loss: 0.1089, Train MSE: 0.1089, r (train): 0.8040, Test MSE: 0.1293, r (test): 0.0792
Epoch: 28, Training Loss: 0.0604, Train MSE: 0.0604, r (train): 0.8102, Test MSE: 0.0947, r (test): 0.1499
Epoch: 29, Training Loss: 0.0445, Train MSE: 0.0445, r (train): 0.8401, Test MSE: 0.1014, r (test): -0.0569
Epoch: 30, Training Loss: 0.0773, Train MSE: 0.0773, r (train): 0.8293, Test MSE: 0.1271, r (test): -0.0640
Epoch: 31, Training Loss: 0.0920, Train MSE: 0.0920, r (train): 0.8573, Test MSE: 0.1345, r (test): 0.0322
Epoch: 32, Training Loss: 0.1103, Train MSE: 0.1103, r (train): 0.8532, Test MSE: 0.1368, r (test): 0.2228
Epoch: 33, Training Loss: 0.0553, Train MSE: 0.0553, r (train): 0.8554, Test MSE: 0.0940, r (test): 0.1245
Epoch: 34, Training Loss: 0.0438, Train MSE: 0.0438, r (train): 0.8775, Test MSE: 0.1168, r (test): -0.1197
Epoch: 35, Training Loss: 0.0757, Train MSE: 0.0757, r (train): 0.8619, Test MSE: 0.1369, r (test): -0.0791
Epoch: 36, Training Loss: 0.0960, Train MSE: 0.0960, r (train): 0.8441, Test MSE: 0.1509, r (test): -0.0547
Epoch: 37, Training Loss: 0.1170, Train MSE: 0.1170, r (train): 0.8275, Test MSE: 0.1636, r (test): 0.0095
Epoch: 38, Training Loss: 0.0714, Train MSE: 0.0714, r (train): 0.8570, Test MSE: 0.1268, r (test): -0.0325
Epoch: 39, Training Loss: 0.0621, Train MSE: 0.0621, r (train): 0.8399, Test MSE: 0.1085, r (test): -0.0197
Epoch: 40, Training Loss: 0.0689, Train MSE: 0.0689, r (train): 0.8328, Test MSE: 0.1557, r (test): -0.2369
Epoch: 41, Training Loss: 0.1026, Train MSE: 0.1026, r (train): 0.8498, Test MSE: 0.1389, r (test): -0.0686
Epoch: 42, Training Loss: 0.0575, Train MSE: 0.0575, r (train): 0.8405, Test MSE: 0.0989, r (test): 0.0529
Epoch: 43, Training Loss: 0.0605, Train MSE: 0.0605, r (train): 0.8776, Test MSE: 0.0911, r (test): 0.0861
Epoch: 44, Training Loss: 0.0249, Train MSE: 0.0249, r (train): 0.8802, Test MSE: 0.1066, r (test): -0.2276
Epoch: 45, Training Loss: 0.0479, Train MSE: 0.0479, r (train): 0.8735, Test MSE: 0.1161, r (test): -0.1788
Epoch: 46, Training Loss: 0.0361, Train MSE: 0.0361, r (train): 0.8922, Test MSE: 0.0832, r (test): 0.0544
Epoch: 47, Training Loss: 0.0222, Train MSE: 0.0222, r (train): 0.8726, Test MSE: 0.1026, r (test): -0.1847
Epoch: 48, Training Loss: 0.0310, Train MSE: 0.0310, r (train): 0.8817, Test MSE: 0.0810, r (test): 0.0654
Epoch: 49, Training Loss: 0.0242, Train MSE: 0.0242, r (train): 0.8708, Test MSE: 0.0799, r (test): 0.1165
Epoch: 50, Training Loss: 0.0265, Train MSE: 0.0265, r (train): 0.8488, Test MSE: 0.0823, r (test): 0.1538
Epoch: 51, Training Loss: 0.0242, Train MSE: 0.0242, r (train): 0.8322, Test MSE: 0.1083, r (test): -0.0316
Epoch: 52, Training Loss: 0.0264, Train MSE: 0.0264, r (train): 0.8015, Test MSE: 0.1095, r (test): -0.2686
Epoch: 53, Training Loss: 0.0264, Train MSE: 0.0264, r (train): 0.8574, Test MSE: 0.0787, r (test): 0.1305
Epoch: 54, Training Loss: 0.0241, Train MSE: 0.0241, r (train): 0.8619, Test MSE: 0.0881, r (test): 0.0394
Epoch: 55, Training Loss: 0.0176, Train MSE: 0.0176, r (train): 0.8740, Test MSE: 0.0960, r (test): -0.0830
Epoch: 56, Training Loss: 0.0324, Train MSE: 0.0324, r (train): 0.8390, Test MSE: 0.0954, r (test): -0.1571
Epoch: 57, Training Loss: 0.0574, Train MSE: 0.0574, r (train): 0.8862, Test MSE: 0.1082, r (test): -0.0296
Epoch: 58, Training Loss: 0.0840, Train MSE: 0.0840, r (train): 0.8931, Test MSE: 0.1310, r (test): 0.0201
Epoch: 59, Training Loss: 0.0931, Train MSE: 0.0931, r (train): 0.8806, Test MSE: 0.1403, r (test): 0.0281
Epoch: 60, Training Loss: 0.1002, Train MSE: 0.1002, r (train): 0.8588, Test MSE: 0.1495, r (test): 0.0020
Epoch: 61, Training Loss: 0.1312, Train MSE: 0.1312, r (train): 0.8735, Test MSE: 0.2051, r (test): -0.0539
Epoch: 62, Training Loss: 0.1317, Train MSE: 0.1317, r (train): 0.8921, Test MSE: 0.1853, r (test): 0.0772
Epoch: 63, Training Loss: 0.0788, Train MSE: 0.0788, r (train): 0.8848, Test MSE: 0.1156, r (test): 0.1137
Epoch: 64, Training Loss: 0.0540, Train MSE: 0.0540, r (train): 0.8491, Test MSE: 0.1090, r (test): 0.0637
Epoch: 65, Training Loss: 0.0336, Train MSE: 0.0336, r (train): 0.8680, Test MSE: 0.0683, r (test): 0.3122
Epoch: 66, Training Loss: 0.0253, Train MSE: 0.0253, r (train): 0.8722, Test MSE: 0.0784, r (test): 0.2273
Epoch: 67, Training Loss: 0.0309, Train MSE: 0.0309, r (train): 0.8181, Test MSE: 0.0969, r (test): 0.3210
Epoch: 68, Training Loss: 0.0329, Train MSE: 0.0329, r (train): 0.8150, Test MSE: 0.0934, r (test): 0.3038
Epoch: 69, Training Loss: 0.0389, Train MSE: 0.0389, r (train): 0.8019, Test MSE: 0.1247, r (test): 0.2253
Epoch: 70, Training Loss: 0.0288, Train MSE: 0.0288, r (train): 0.8359, Test MSE: 0.1146, r (test): 0.2021
Epoch: 71, Training Loss: 0.0208, Train MSE: 0.0208, r (train): 0.8481, Test MSE: 0.0883, r (test): 0.0909
Epoch: 72, Training Loss: 0.0286, Train MSE: 0.0286, r (train): 0.8439, Test MSE: 0.0950, r (test): -0.0382
Epoch: 73, Training Loss: 0.0563, Train MSE: 0.0563, r (train): 0.8871, Test MSE: 0.1214, r (test): -0.0237
Epoch: 74, Training Loss: 0.0525, Train MSE: 0.0525, r (train): 0.9060, Test MSE: 0.0954, r (test): 0.1184
Epoch: 75, Training Loss: 0.0427, Train MSE: 0.0427, r (train): 0.9064, Test MSE: 0.0985, r (test): 0.1576
Epoch: 76, Training Loss: 0.0187, Train MSE: 0.0187, r (train): 0.9178, Test MSE: 0.0743, r (test): 0.2797
Epoch: 77, Training Loss: 0.0235, Train MSE: 0.0235, r (train): 0.9020, Test MSE: 0.1063, r (test): 0.2742
Epoch: 78, Training Loss: 0.0235, Train MSE: 0.0235, r (train): 0.8753, Test MSE: 0.1106, r (test): 0.3628
Epoch: 79, Training Loss: 0.0207, Train MSE: 0.0207, r (train): 0.8603, Test MSE: 0.0918, r (test): 0.3228
Epoch: 80, Training Loss: 0.0123, Train MSE: 0.0123, r (train): 0.9208, Test MSE: 0.0927, r (test): -0.1461
Epoch: 81, Training Loss: 0.0377, Train MSE: 0.0377, r (train): 0.9073, Test MSE: 0.0975, r (test): -0.0841
Epoch: 82, Training Loss: 0.0243, Train MSE: 0.0243, r (train): 0.9234, Test MSE: 0.0804, r (test): 0.0462
Epoch: 83, Training Loss: 0.0153, Train MSE: 0.0153, r (train): 0.9143, Test MSE: 0.0771, r (test): 0.2322
Epoch: 84, Training Loss: 0.0278, Train MSE: 0.0278, r (train): 0.8968, Test MSE: 0.1126, r (test): 0.1939
Epoch: 85, Training Loss: 0.0355, Train MSE: 0.0355, r (train): 0.8926, Test MSE: 0.1357, r (test): 0.4374
Epoch: 86, Training Loss: 0.0142, Train MSE: 0.0142, r (train): 0.9072, Test MSE: 0.0862, r (test): 0.3399
Epoch: 87, Training Loss: 0.0191, Train MSE: 0.0191, r (train): 0.8836, Test MSE: 0.0898, r (test): -0.0644
Epoch: 88, Training Loss: 0.0200, Train MSE: 0.0200, r (train): 0.9163, Test MSE: 0.0823, r (test): -0.0678
Epoch: 89, Training Loss: 0.0133, Train MSE: 0.0133, r (train): 0.9285, Test MSE: 0.0718, r (test): 0.2001
Epoch: 90, Training Loss: 0.0268, Train MSE: 0.0268, r (train): 0.9160, Test MSE: 0.1007, r (test): 0.3773
Epoch: 91, Training Loss: 0.0542, Train MSE: 0.0542, r (train): 0.9056, Test MSE: 0.1525, r (test): 0.4350
Epoch: 92, Training Loss: 0.0303, Train MSE: 0.0303, r (train): 0.8938, Test MSE: 0.1326, r (test): 0.3820
Epoch: 93, Training Loss: 0.0147, Train MSE: 0.0147, r (train): 0.9027, Test MSE: 0.0999, r (test): -0.1002
Epoch: 94, Training Loss: 0.0120, Train MSE: 0.0120, r (train): 0.9314, Test MSE: 0.0766, r (test): 0.2130
Epoch: 95, Training Loss: 0.0127, Train MSE: 0.0127, r (train): 0.9382, Test MSE: 0.0812, r (test): 0.0705
Epoch: 96, Training Loss: 0.0119, Train MSE: 0.0119, r (train): 0.9289, Test MSE: 0.0678, r (test): 0.2446
Epoch: 97, Training Loss: 0.0095, Train MSE: 0.0095, r (train): 0.9424, Test MSE: 0.0661, r (test): 0.3756
Epoch: 98, Training Loss: 0.0097, Train MSE: 0.0097, r (train): 0.9415, Test MSE: 0.0775, r (test): 0.2925
Epoch: 99, Training Loss: 0.0204, Train MSE: 0.0204, r (train): 0.9232, Test MSE: 0.1066, r (test): 0.2959
Predicted tensors for training set: 
tensor([ 0.7123,  0.6271, -0.0136,  0.3516,  0.5874,  0.2618,  0.5387,  0.5758,
         0.1994,  0.6609,  0.7597, -0.0019,  0.5655,  0.2702,  0.4408,  0.4968,
         0.4739,  0.4747,  0.5774,  0.0119,  0.2309,  0.0392,  0.2980,  0.3160,
         0.2694, -0.0789,  0.6764,  0.6878,  0.3474,  0.4151,  0.0295,  0.6092,
         0.4196,  0.5607,  0.0878,  0.3052,  0.7685,  0.7490,  0.0586,  0.5381,
         0.2508,  0.5928,  0.1715,  0.0791,  0.7484, -0.0807,  0.1904,  0.4490,
         0.8439, -0.0420,  0.5453,  0.6273,  0.2618,  0.7595,  0.2949,  0.5221,
         0.7967,  0.4768,  0.7117,  0.8083,  0.7744,  0.1442,  0.1272,  0.7319,
         0.6462,  0.8725,  0.9250,  0.4336,  0.5491,  0.4270,  0.5460,  0.0678])
Target tensorsfor training set: 
tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478])
Correlation for training set: 0.923224903778651
Predicted tensors for test set: 
tensor([0.4857, 0.4396, 0.5938, 0.4323, 0.4086, 0.4044, 0.2466, 0.2835, 0.4138,
        0.4114, 0.4479, 0.4539, 0.3481, 0.5832, 0.4298, 0.2310, 0.5479, 0.3144])
Target tensors for test set: 
tensor([0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271])
Correlation for test set: 0.2958622451276108
Seed: 37
Fold losses: [tensor(0.0104), tensor(0.0168), tensor(0.0278), tensor(0.0190), tensor(0.0204)]
Fold MSE values: [tensor(0.0104), tensor(0.0168), tensor(0.0278), tensor(0.0190), tensor(0.0204)]
Target training values: [tensor([0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271]), tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271]), tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271]), tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.7791, 0.5658, 0.5300, 0.9621, 0.4526, 0.9215, 0.8524, 0.4654, 0.5564,
        0.5779, 0.1055, 0.7462, 0.8418, 0.9150, 0.9072, 0.1295, 0.6576, 0.2271]), tensor([0.7371, 0.6671, 0.0636, 0.4373, 0.7144, 0.3453, 0.6465, 0.2255, 0.3077,
        0.7950, 0.9656, 0.2169, 0.5780, 0.4640, 0.7596, 0.7270, 0.6577, 0.8411,
        0.9535, 0.2649, 0.4341, 0.2916, 0.5187, 0.5220, 0.4440, 0.0389, 0.8728,
        0.7901, 0.5102, 0.5573, 0.1218, 0.6595, 0.4993, 0.6992, 0.2464, 0.4036,
        0.8453, 0.8561, 0.1493, 0.7125, 0.3309, 0.7171, 0.2594, 0.1294, 0.9127,
        0.0246, 0.2394, 0.5178, 0.9492, 0.0763, 0.6240, 0.6846, 0.3174, 0.8391,
        0.3829, 0.5783, 0.8363, 0.5023, 0.7507, 0.8556, 0.7497, 0.0981, 0.1360,
        0.7372, 0.6199, 0.8988, 0.9117, 0.4149, 0.5719, 0.4513, 0.4818, 0.0478])]
Prediction training values: [tensor([ 8.6313e-01,  1.3452e-01,  3.3271e-01,  2.2030e-01,  3.9496e-01,
         4.0623e-01,  3.4103e-01,  6.2472e-02,  6.8646e-01,  5.8690e-01,
         4.1222e-01,  3.7437e-01,  4.7428e-02,  4.4406e-01,  3.0966e-01,
         5.1551e-01, -1.4270e-02,  3.2168e-01,  7.5469e-01,  6.6799e-01,
         7.6315e-02,  6.0287e-01,  2.6874e-01,  6.4501e-01,  2.4481e-01,
         1.9183e-01,  9.3378e-01,  4.9925e-02,  3.0520e-01,  5.9861e-01,
         9.1164e-01,  1.8792e-01,  6.2990e-01,  6.2050e-01,  2.8794e-01,
         9.1708e-01,  3.8007e-01,  5.6607e-01,  7.5789e-01,  4.7223e-01,
         6.4708e-01,  7.6099e-01,  6.3970e-01, -3.7173e-02,  3.7463e-02,
         6.0972e-01,  4.7996e-01,  8.4193e-01,  8.1452e-01,  2.7096e-01,
         4.6572e-01,  3.7205e-01,  3.7590e-01, -8.8655e-04,  6.7258e-01,
         5.9297e-01,  5.3322e-01,  1.0523e+00,  4.6715e-01,  9.4743e-01,
         9.6149e-01,  5.7350e-01,  5.3957e-01,  6.3710e-01,  8.5311e-02,
         7.4201e-01,  7.7251e-01,  9.8130e-01,  9.0402e-01,  1.5296e-01,
         5.5973e-01,  1.3549e-01]), tensor([0.7640, 0.7500, 0.1588, 0.5768, 0.7183, 0.4610, 0.7197, 0.4360, 0.4410,
        0.8597, 1.0111, 0.3415, 0.7103, 0.5186, 0.8461, 0.8000, 0.7851, 0.9196,
        0.8808, 0.8938, 0.2758, 0.6979, 0.3848, 0.7132, 0.3548, 0.1860, 0.8041,
        0.0883, 0.2997, 0.4697, 0.8897, 0.0686, 0.6115, 0.6720, 0.4157, 0.8079,
        0.5121, 0.6496, 0.9164, 0.6392, 0.8645, 1.0218, 0.9547, 0.3926, 0.3947,
        0.9333, 0.9267, 1.1194, 1.0405, 0.6573, 0.7702, 0.7129, 0.7288, 0.3800,
        0.9867, 0.6791, 0.6779, 1.0802, 0.5399, 0.9303, 0.9053, 0.5236, 0.6114,
        0.5958, 0.1213, 0.7507, 0.7959, 0.8580, 0.8830, 0.1477, 0.7571, 0.2615]), tensor([0.8828, 0.6687, 0.0929, 0.4220, 0.6130, 0.2335, 0.5514, 0.2093, 0.2082,
        0.7505, 0.8836, 0.0829, 0.4983, 0.3606, 0.6618, 0.6317, 0.5741, 0.8251,
        0.9110, 0.2179, 0.3727, 0.2737, 0.5471, 0.5306, 0.4911, 0.0610, 0.9653,
        0.8896, 0.5868, 0.6629, 0.1353, 0.7811, 0.5690, 0.7776, 0.3226, 0.5625,
        0.5560, 0.8510, 1.1322, 0.7546, 1.0402, 1.2550, 1.0876, 0.3484, 0.4080,
        1.0431, 0.8939, 1.2200, 1.2369, 0.7387, 0.8142, 0.7203, 0.6727, 0.2966,
        1.0229, 0.7332, 0.7413, 1.1705, 0.5882, 1.0468, 1.0441, 0.5338, 0.7022,
        0.6774, 0.1671, 0.8300, 0.8860, 0.9595, 0.9076, 0.1845, 0.6335, 0.2629]), tensor([ 0.6798,  0.6295,  0.0967,  0.4057,  0.5342,  0.3277,  0.5244,  0.1768,
         0.2467,  0.5939,  0.8052,  0.1964,  0.4438,  0.3417,  0.4463,  0.5255,
         0.4781,  0.3351,  0.5553,  0.2261,  0.3512,  0.2202,  0.4644,  0.4467,
         0.4667,  0.0695,  0.7644,  0.8170,  0.4658,  0.4670,  0.0937,  0.7333,
         0.5709,  0.6340,  0.1430,  0.4114,  0.8586,  0.7174,  0.1036,  0.6082,
         0.2972,  0.5969,  0.2091,  0.0858,  0.7534, -0.0845,  0.1138,  0.3535,
         0.7712, -0.1162,  0.4779,  0.4684,  0.1906,  0.6329,  0.5805,  0.4080,
         0.2945,  0.8394,  0.4240,  0.7784,  0.7370,  0.3806,  0.4453,  0.5180,
         0.0682,  0.6876,  0.8084,  0.9534,  0.8559,  0.0595,  0.6486,  0.0986]), tensor([ 0.7123,  0.6271, -0.0136,  0.3516,  0.5874,  0.2618,  0.5387,  0.5758,
         0.1994,  0.6609,  0.7597, -0.0019,  0.5655,  0.2702,  0.4408,  0.4968,
         0.4739,  0.4747,  0.5774,  0.0119,  0.2309,  0.0392,  0.2980,  0.3160,
         0.2694, -0.0789,  0.6764,  0.6878,  0.3474,  0.4151,  0.0295,  0.6092,
         0.4196,  0.5607,  0.0878,  0.3052,  0.7685,  0.7490,  0.0586,  0.5381,
         0.2508,  0.5928,  0.1715,  0.0791,  0.7484, -0.0807,  0.1904,  0.4490,
         0.8439, -0.0420,  0.5453,  0.6273,  0.2618,  0.7595,  0.2949,  0.5221,
         0.7967,  0.4768,  0.7117,  0.8083,  0.7744,  0.1442,  0.1272,  0.7319,
         0.6462,  0.8725,  0.9250,  0.4336,  0.5491,  0.4270,  0.5460,  0.0678])]
Target values: [array([0.73709923, 0.6671056 , 0.06358391, 0.4372734 , 0.71435624,
       0.34531343, 0.6464906 , 0.2254639 , 0.30766785, 0.79497874,
       0.96564525, 0.21692123, 0.578045  , 0.46398443, 0.75962484,
       0.72703534, 0.65769196, 0.84113044], dtype=float32), array([0.95346546, 0.2649091 , 0.43409458, 0.29163042, 0.518717  ,
       0.5220161 , 0.44401234, 0.03887437, 0.8728059 , 0.7900961 ,
       0.51015127, 0.55726975, 0.12180944, 0.659493  , 0.4993471 ,
       0.69921327, 0.24636388, 0.40355092], dtype=float32), array([0.84525365, 0.85610735, 0.14931566, 0.71252435, 0.33092642,
       0.71714455, 0.25936916, 0.12937951, 0.912732  , 0.02463444,
       0.23939352, 0.51780254, 0.9491663 , 0.07633217, 0.62399   ,
       0.6846425 , 0.31742746, 0.8390776 ], dtype=float32), array([0.38285765, 0.57832706, 0.83626515, 0.50225437, 0.75073236,
       0.85557973, 0.7497406 , 0.09805249, 0.1360485 , 0.73719215,
       0.6198749 , 0.89876264, 0.9116711 , 0.41493568, 0.57190746,
       0.45128736, 0.48182514, 0.04781396], dtype=float32), array([0.77910316, 0.5658469 , 0.52996147, 0.96213573, 0.45263878,
       0.9215425 , 0.8524316 , 0.46544507, 0.55641776, 0.5778506 ,
       0.10552448, 0.7462256 , 0.8417677 , 0.91498566, 0.9071598 ,
       0.12948532, 0.6576234 , 0.22711647], dtype=float32)]
Prediction values: [array([0.1999002 , 0.51843244, 0.15622759, 0.47639823, 0.2764335 ,
       0.55371296, 0.60732955, 0.9807597 , 0.5603926 , 0.50877726,
       0.5173128 , 0.52921313, 0.70504904, 0.50943524, 0.5338055 ,
       0.4562346 , 0.10025705, 0.40127015], dtype=float32), array([0.68397045, 0.66986513, 0.5778587 , 0.7879463 , 0.6918984 ,
       0.69832766, 0.6656939 , 0.57300776, 0.73560375, 0.5555989 ,
       0.6723455 , 0.57469374, 0.6538634 , 0.7138284 , 0.5542876 ,
       0.736257  , 0.9020898 , 0.69792664], dtype=float32), array([0.5676046 , 0.52956146, 0.6170126 , 0.61396044, 0.78868926,
       0.4885308 , 0.72454613, 0.716104  , 0.71147513, 0.6524561 ,
       0.54921156, 0.5564421 , 0.35631317, 0.77982444, 0.7857688 ,
       0.77140915, 0.7342039 , 0.30516192], dtype=float32), array([0.28185558, 0.46307838, 0.3703947 , 0.54990685, 0.44122887,
       0.29743877, 0.54657835, 0.3389092 , 0.5105638 , 0.37008363,
       0.3915407 , 0.48278987, 0.53999174, 0.54829246, 0.29904872,
       0.277413  , 0.45887858, 0.43487102], dtype=float32), array([0.48572463, 0.43963587, 0.5938425 , 0.43225467, 0.40862516,
       0.4043775 , 0.24655157, 0.28351983, 0.41375396, 0.41136235,
       0.44789293, 0.4539159 , 0.3481259 , 0.583236  , 0.42981583,
       0.23100862, 0.5478641 , 0.3143628 ], dtype=float32)]
Time taken: 979.663501739502 seconds
